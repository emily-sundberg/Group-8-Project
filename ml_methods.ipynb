{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"ML Methods\"\n",
        "format:\n",
        "  html:\n",
        "    code-fold: true\n",
        "    code-summary: \"Show code\"\n",
        "    code-tools: true\n",
        "---"
      ],
      "id": "8d52b6e0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: setup-topic-2-2\n",
        "#| warning: false\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import plotly.io as pio\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import mean_squared_error, r2_score, silhouette_score\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set Plotly theme\n",
        "pio.templates.default = \"plotly_white\"\n",
        "\n",
        "print(\"âœ“ All libraries loaded successfully!\")"
      ],
      "id": "setup-topic-2-2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Loading and Exploration"
      ],
      "id": "40f630fd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: load-data-topic-2-2\n",
        "\n",
        "# Load lightcast job postings data\n",
        "df = pd.read_csv('data/lightcast_job_postings.csv')\n",
        "\n",
        "print(f\"Dataset Shape: {df.shape[0]:,} rows Ã— {df.shape[1]} columns\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "df.head()"
      ],
      "id": "load-data-topic-2-2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: data-inspection\n",
        "\n",
        "# Check data quality\n",
        "print(\"=\"*80)\n",
        "print(\"DATA QUALITY ASSESSMENT\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Key columns for analysis\n",
        "key_columns = ['SALARY', 'STATE', 'TITLE', 'NAICS_2022_2', 'SOC_2', 'ONET', 'LIGHTCAST_SECTORS']\n",
        "\n",
        "info_df = pd.DataFrame({\n",
        "    'Column': key_columns,\n",
        "    'Missing': [df[col].isnull().sum() if col in df.columns else 'N/A' for col in key_columns],\n",
        "    'Missing %': [f\"{(df[col].isnull().sum() / len(df) * 100):.2f}%\" if col in df.columns else 'N/A' for col in key_columns],\n",
        "    'Unique Values': [df[col].nunique() if col in df.columns else 'N/A' for col in key_columns]\n",
        "})\n",
        "\n",
        "print(info_df.to_string(index=False))\n",
        "\n",
        "# Salary statistics\n",
        "if 'SALARY' in df.columns:\n",
        "    print(f\"\\nSalary Statistics:\")\n",
        "    print(f\"  Mean: ${df['SALARY'].mean():,.2f}\")\n",
        "    print(f\"  Median: ${df['SALARY'].median():,.2f}\")\n",
        "    print(f\"  Std Dev: ${df['SALARY'].std():,.2f}\")\n",
        "    print(f\"  Range: ${df['SALARY'].min():,.2f} - ${df['SALARY'].max():,.2f}\")"
      ],
      "id": "data-inspection",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Preprocessing"
      ],
      "id": "e804207a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: preprocessing\n",
        "\n",
        "# Create working copy\n",
        "df_clean = df.copy()\n",
        "\n",
        "# Remove rows with missing salary or state\n",
        "required_cols = ['SALARY', 'STATE']\n",
        "initial_rows = len(df_clean)\n",
        "df_clean = df_clean.dropna(subset=required_cols)\n",
        "removed_rows = initial_rows - len(df_clean)\n",
        "\n",
        "print(f\"Removed {removed_rows:,} rows with missing salary or state data\")\n",
        "print(f\"Final dataset: {len(df_clean):,} rows\")"
      ],
      "id": "preprocessing",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: political-leaning-creation\n",
        "#| code-fold: true\n",
        "\n",
        "# State name to abbreviation mapping\n",
        "state_to_abbrev = {\n",
        "    'Alabama': 'AL', 'Alaska': 'AK', 'Arizona': 'AZ', 'Arkansas': 'AR',\n",
        "    'California': 'CA', 'Colorado': 'CO', 'Connecticut': 'CT', 'Delaware': 'DE',\n",
        "    'Florida': 'FL', 'Georgia': 'GA', 'Hawaii': 'HI', 'Idaho': 'ID',\n",
        "    'Illinois': 'IL', 'Indiana': 'IN', 'Iowa': 'IA', 'Kansas': 'KS',\n",
        "    'Kentucky': 'KY', 'Louisiana': 'LA', 'Maine': 'ME', 'Maryland': 'MD',\n",
        "    'Massachusetts': 'MA', 'Michigan': 'MI', 'Minnesota': 'MN', 'Mississippi': 'MS',\n",
        "    'Missouri': 'MO', 'Montana': 'MT', 'Nebraska': 'NE', 'Nevada': 'NV',\n",
        "    'New Hampshire': 'NH', 'New Jersey': 'NJ', 'New Mexico': 'NM', 'New York': 'NY',\n",
        "    'North Carolina': 'NC', 'North Dakota': 'ND', 'Ohio': 'OH', 'Oklahoma': 'OK',\n",
        "    'Oregon': 'OR', 'Pennsylvania': 'PA', 'Rhode Island': 'RI', 'South Carolina': 'SC',\n",
        "    'South Dakota': 'SD', 'Tennessee': 'TN', 'Texas': 'TX', 'Utah': 'UT',\n",
        "    'Vermont': 'VT', 'Virginia': 'VA', 'Washington': 'WA', 'West Virginia': 'WV',\n",
        "    'Wisconsin': 'WI', 'Wyoming': 'WY', 'District of Columbia': 'DC'\n",
        "}\n",
        "\n",
        "# Political classifications based on 2024 presidential election\n",
        "red_states = [\n",
        "    'AL', 'AK', 'AR', 'FL', 'ID', 'IN', 'IA', 'KS', 'KY', \n",
        "    'LA', 'MS', 'MO', 'MT', 'NE', 'ND', 'OH', 'OK', 'SC', \n",
        "    'SD', 'TN', 'TX', 'UT', 'WV', 'WY'\n",
        "]\n",
        "\n",
        "blue_states = [\n",
        "    'CA', 'CO', 'CT', 'DE', 'HI', 'IL', 'ME', 'MD', 'MA', \n",
        "    'MI', 'MN', 'NH', 'NJ', 'NM', 'NY', 'OR', 'PA', 'RI', \n",
        "    'VT', 'VA', 'WA', 'WI', 'DC'\n",
        "]\n",
        "\n",
        "swing_states = ['AZ', 'GA', 'NC', 'NV']\n",
        "\n",
        "def assign_political_leaning(state):\n",
        "    \"\"\"Classify state by political leaning\"\"\"\n",
        "    if pd.isna(state):\n",
        "        return 'Unknown'\n",
        "    \n",
        "    # Convert to string and clean\n",
        "    state_str = str(state).strip()\n",
        "    \n",
        "    # Try to get abbreviation if full name provided\n",
        "    state_abbrev = state_to_abbrev.get(state_str, state_str.upper())\n",
        "    \n",
        "    # Classify\n",
        "    if state_abbrev in red_states:\n",
        "        return 'Red'\n",
        "    elif state_abbrev in blue_states:\n",
        "        return 'Blue'\n",
        "    elif state_abbrev in swing_states:\n",
        "        return 'Swing'\n",
        "    else:\n",
        "        return 'Other'\n",
        "\n",
        "# Apply classification\n",
        "df_clean['political_leaning'] = df_clean['STATE'].apply(assign_political_leaning)\n",
        "\n",
        "# Display results\n",
        "print(\"=\"*60)\n",
        "print(\"POLITICAL LEANING DISTRIBUTION\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nDistribution:\")\n",
        "print(df_clean['political_leaning'].value_counts())\n",
        "print(f\"\\nPercentage:\")\n",
        "print((df_clean['political_leaning'].value_counts() / len(df_clean) * 100).round(2))\n",
        "\n",
        "# Debug: Check for \"Other\" classifications\n",
        "if df_clean['political_leaning'].value_counts().get('Other', 0) > 0:\n",
        "    print(f\"\\nâš ï¸ States classified as 'Other':\")\n",
        "    other_states = df_clean[df_clean['political_leaning'] == 'Other']['STATE'].value_counts()\n",
        "    print(other_states.head(10))"
      ],
      "id": "political-leaning-creation",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: visualize-political-distribution\n",
        "\n",
        "# Visualize political distribution\n",
        "fig = px.pie(\n",
        "    values=df_clean['political_leaning'].value_counts().values,\n",
        "    names=df_clean['political_leaning'].value_counts().index,\n",
        "    title='Distribution of Jobs by Political Leaning of State',\n",
        "    hole=0.4,\n",
        "    color_discrete_map={'Red': '#FF6B6B', 'Blue': '#4ECDC4', 'Swing': '#FFD93D', 'Other': '#95A5A6'}\n",
        ")\n",
        "fig.update_layout(template=\"plotly_white\", height=400)\n",
        "fig.show()"
      ],
      "id": "visualize-political-distribution",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## K-Means Clustering (unsupervised)\n",
        "\n",
        "### Setup and Feature Engineering\n"
      ],
      "id": "f293a2d3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: clustering-reference-label\n",
        "\n",
        "# Determine which reference label to use\n",
        "reference_label = None\n",
        "for label in ['SOC_2', 'NAICS_2022_2', 'ONET', 'LIGHTCAST_SECTORS']:\n",
        "    if label in df_clean.columns and df_clean[label].notna().sum() > 0:\n",
        "        reference_label = label\n",
        "        print(f\"âœ“ Using {label} as reference label\")\n",
        "        break\n",
        "\n",
        "if reference_label is None:\n",
        "    print(\"Using TITLE as reference.\")\n",
        "    reference_label = 'TITLE'\n",
        "\n",
        "print(f\"\\nReference Label: {reference_label}\")\n",
        "print(f\"Unique values: {df_clean[reference_label].nunique():,}\")\n",
        "print(f\"\\nTop 10 {reference_label} categories:\")\n",
        "print(df_clean[reference_label].value_counts().head(10))"
      ],
      "id": "clustering-reference-label",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: clustering-feature-engineering\n",
        "\n",
        "# Prepare features for clustering\n",
        "df_cluster = df_clean.copy()\n",
        "\n",
        "# Encode categorical variables\n",
        "encoders = {}\n",
        "categorical_cols = ['STATE', 'TITLE', 'political_leaning', 'LIGHTCAST_SECTORS']\n",
        "\n",
        "print(\"\\nEncoding categorical variables for clustering:\")\n",
        "for col in categorical_cols:\n",
        "    if col in df_cluster.columns:\n",
        "        le = LabelEncoder()\n",
        "        df_cluster[f'{col}_encoded'] = le.fit_transform(\n",
        "            df_cluster[col].fillna('Unknown').astype(str)\n",
        "        )\n",
        "        encoders[col] = le\n",
        "        print(f\"  âœ“ Encoded: {col}\")\n",
        "\n",
        "# Select clustering features\n",
        "clustering_features = ['SALARY']\n",
        "\n",
        "for col in categorical_cols:\n",
        "    encoded_col = f'{col}_encoded'\n",
        "    if encoded_col in df_cluster.columns:\n",
        "        clustering_features.append(encoded_col)\n",
        "\n",
        "# Add years of experience if available\n",
        "if 'MIN_YEARS_EXPERIENCE' in df_cluster.columns:\n",
        "    df_cluster['MIN_YEARS_EXPERIENCE'] = pd.to_numeric(\n",
        "        df_cluster['MIN_YEARS_EXPERIENCE'], errors='coerce'\n",
        "    )\n",
        "    clustering_features.append('MIN_YEARS_EXPERIENCE')\n",
        "\n",
        "print(f\"\\nFinal Clustering Features ({len(clustering_features)}):\")\n",
        "for i, feature in enumerate(clustering_features, 1):\n",
        "    print(f\"  {i}. {feature}\")\n",
        "\n",
        "# Prepare feature matrix\n",
        "X_cluster = df_cluster[clustering_features].fillna(df_cluster[clustering_features].mean())\n",
        "print(f\"\\nFeature Matrix Shape: {X_cluster.shape}\")"
      ],
      "id": "clustering-feature-engineering",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Determine Optimal K\n"
      ],
      "id": "534f5217"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: determine-optimal-clusters\n",
        "\n",
        "# Determine optimal number of clusters using Elbow Method and Silhouette Score\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_cluster)\n",
        "\n",
        "K_range = range(2, 11)\n",
        "inertias = []\n",
        "silhouette_scores = []\n",
        "\n",
        "print(\"Testing different numbers of clusters...\")\n",
        "print(f\"{'k':<5} {'Inertia':<15} {'Silhouette Score'}\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "for k in K_range:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    kmeans.fit(X_scaled)\n",
        "    inertias.append(kmeans.inertia_)\n",
        "    sil_score = silhouette_score(X_scaled, kmeans.labels_)\n",
        "    silhouette_scores.append(sil_score)\n",
        "    print(f\"{k:<5} {kmeans.inertia_:<15.2f} {sil_score:.4f}\")\n",
        "\n",
        "optimal_k = list(K_range)[silhouette_scores.index(max(silhouette_scores))]\n",
        "print(f\"\\nðŸ’¡ Optimal k based on Silhouette Score: {optimal_k}\")"
      ],
      "id": "determine-optimal-clusters",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: plot-elbow-silhouette\n",
        "\n",
        "# Visualize elbow curve and silhouette scores\n",
        "fig = make_subplots(\n",
        "    rows=1, cols=2,\n",
        "    subplot_titles=('Elbow Method', 'Silhouette Score Method')\n",
        ")\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=list(K_range), y=inertias, mode='lines+markers', \n",
        "               name='Inertia', line=dict(color='blue')),\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=list(K_range), y=silhouette_scores, mode='lines+markers', \n",
        "               name='Silhouette', line=dict(color='orange')),\n",
        "    row=1, col=2\n",
        ")\n",
        "\n",
        "fig.update_xaxes(title_text=\"Number of Clusters (k)\", row=1, col=1)\n",
        "fig.update_xaxes(title_text=\"Number of Clusters (k)\", row=1, col=2)\n",
        "fig.update_yaxes(title_text=\"Inertia\", row=1, col=1)\n",
        "fig.update_yaxes(title_text=\"Silhouette Score\", row=1, col=2)\n",
        "\n",
        "fig.update_layout(\n",
        "    height=400, \n",
        "    showlegend=False, \n",
        "    template=\"plotly_white\",\n",
        "    title_text=\"Determining Optimal Number of Clusters\"\n",
        ")\n",
        "fig.show()"
      ],
      "id": "plot-elbow-silhouette",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cluster Analysis\n"
      ],
      "id": "1a2ca545"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: perform-kmeans\n",
        "\n",
        "# Perform KMeans clustering with k=5 (per assignment requirements)\n",
        "n_clusters = 5\n",
        "\n",
        "print(f\"Performing KMeans with k={n_clusters} clusters...\")\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
        "df_cluster['cluster'] = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "print(f\"âœ“ Clustering complete!\")\n",
        "print(f\"\\nCluster Distribution:\")\n",
        "cluster_counts = df_cluster['cluster'].value_counts().sort_index()\n",
        "for cluster_id, count in cluster_counts.items():\n",
        "    pct = (count / len(df_cluster)) * 100\n",
        "    print(f\"  Cluster {cluster_id}: {count:,} jobs ({pct:.1f}%)\")"
      ],
      "id": "perform-kmeans",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: visualize-clusters\n",
        "\n",
        "# Visualize clusters (sample for performance)\n",
        "sample_size = min(5000, len(df_cluster))\n",
        "df_sample = df_cluster.sample(sample_size, random_state=42)\n",
        "\n",
        "fig = px.scatter(\n",
        "    df_sample,\n",
        "    x='SALARY',\n",
        "    y='STATE_encoded',\n",
        "    color='cluster',\n",
        "    hover_data=['TITLE', 'political_leaning', reference_label] if 'TITLE' in df_sample.columns else None,\n",
        "    title=f'KMeans Clustering Results (k={n_clusters}, n={sample_size:,} sample)',\n",
        "    labels={'SALARY': 'Annual Salary ($)', 'STATE_encoded': 'State (Encoded)', 'cluster': 'Cluster'},\n",
        "    color_continuous_scale='Viridis'\n",
        ")\n",
        "fig.update_layout(template=\"plotly_white\", height=500)\n",
        "fig.show()"
      ],
      "id": "visualize-clusters",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Findings:**\n",
        "- Cluster 0: Entry-level positions ($50-100k)\n",
        "- Cluster 4: Senior roles ($200k+)\n",
        "- Geographic clustering evident by state encoding\n"
      ],
      "id": "847e2fa8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: cluster-profiling\n",
        "\n",
        "# Analyze cluster characteristics\n",
        "print(\"=\"*80)\n",
        "print(\"CLUSTER PROFILES\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "cluster_profiles = df_cluster.groupby('cluster').agg({\n",
        "    'SALARY': ['mean', 'median', 'std', 'min', 'max'],\n",
        "    'political_leaning': lambda x: x.mode()[0] if len(x.mode()) > 0 else 'Mixed',\n",
        "    'cluster': 'count'\n",
        "})\n",
        "\n",
        "cluster_profiles.columns = [\n",
        "    'Avg_Salary', 'Median_Salary', 'Salary_StdDev', 'Min_Salary', 'Max_Salary',\n",
        "    'Dominant_Political', 'Count'\n",
        "]\n",
        "\n",
        "print(cluster_profiles.round(2))"
      ],
      "id": "cluster-profiling",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: visualize-cluster-profiles\n",
        "\n",
        "# Visualize cluster salary profiles\n",
        "profile_df = cluster_profiles.reset_index()\n",
        "\n",
        "fig = px.bar(\n",
        "    profile_df,\n",
        "    x='cluster',\n",
        "    y='Avg_Salary',\n",
        "    text='Count',\n",
        "    title='Average Salary by Cluster',\n",
        "    labels={'cluster': 'Cluster', 'Avg_Salary': 'Average Salary ($)'},\n",
        "    color='Avg_Salary',\n",
        "    color_continuous_scale='Viridis'\n",
        ")\n",
        "fig.update_traces(texttemplate='n=%{text:,}', textposition='outside')\n",
        "fig.update_layout(template=\"plotly_white\", height=450)\n",
        "fig.show()"
      ],
      "id": "visualize-cluster-profiles",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Multiple Regression Analysis\n"
      ],
      "id": "8168e3d4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: regression-feature-engineering\n",
        "#| code-fold: true\n",
        "#| code-summary: View feature engineering code\n",
        "\n",
        "# Prepare features for salary prediction\n",
        "df_reg = df_clean.copy()\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"FEATURE ENGINEERING FOR SALARY PREDICTION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Encode categorical variables\n",
        "le_reg = {}\n",
        "categorical_features = ['STATE', 'TITLE', 'political_leaning', 'LIGHTCAST_SECTORS']\n",
        "\n",
        "# Add SOC or NAICS if available\n",
        "if 'SOC_2' in df_reg.columns:\n",
        "    categorical_features.append('SOC_2')\n",
        "elif 'NAICS_2022_2' in df_reg.columns:\n",
        "    categorical_features.append('NAICS_2022_2')\n",
        "\n",
        "print(f\"\\nCategorical features to encode ({len(categorical_features)}):\")\n",
        "for col in categorical_features:\n",
        "    if col in df_reg.columns:\n",
        "        le = LabelEncoder()\n",
        "        df_reg[f'{col}_encoded'] = le.fit_transform(\n",
        "            df_reg[col].fillna('Unknown').astype(str)\n",
        "        )\n",
        "        le_reg[col] = le\n",
        "        print(f\"  âœ“ {col}: {df_reg[col].nunique()} unique values\")\n",
        "\n",
        "# Select features for regression\n",
        "feature_cols = []\n",
        "for col in categorical_features:\n",
        "    encoded_col = f'{col}_encoded'\n",
        "    if encoded_col in df_reg.columns:\n",
        "        feature_cols.append(encoded_col)\n",
        "\n",
        "# Add numerical features if available\n",
        "numeric_features = ['MIN_YEARS_EXPERIENCE', 'MAX_YEARS_EXPERIENCE']\n",
        "for num_feat in numeric_features:\n",
        "    if num_feat in df_reg.columns:\n",
        "        df_reg[num_feat] = pd.to_numeric(df_reg[num_feat], errors='coerce')\n",
        "        if df_reg[num_feat].notna().sum() > 0:\n",
        "            feature_cols.append(num_feat)\n",
        "            print(f\"  âœ“ {num_feat}: numeric feature added\")\n",
        "\n",
        "print(f\"\\nðŸ“Š Total Features for Salary Prediction: {len(feature_cols)}\")\n",
        "print(\"\\nFeature List:\")\n",
        "for i, feature in enumerate(feature_cols, 1):\n",
        "    print(f\"  {i}. {feature}\")\n",
        "\n",
        "# Prepare X and y\n",
        "X = df_reg[feature_cols].fillna(df_reg[feature_cols].mean())\n",
        "y = df_reg['SALARY']\n",
        "\n",
        "print(f\"\\nðŸ“ˆ Dataset Statistics:\")\n",
        "print(f\"  â€¢ Feature Matrix Shape: {X.shape}\")\n",
        "print(f\"  â€¢ Target Variable (Salary):\")\n",
        "print(f\"    - Mean: ${y.mean():,.2f}\")\n",
        "print(f\"    - Median: ${y.median():,.2f}\")\n",
        "print(f\"    - Std Dev: ${y.std():,.2f}\")\n",
        "print(f\"    - Range: ${y.min():,.2f} - ${y.max():,.2f}\")"
      ],
      "id": "regression-feature-engineering",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Feature Selection Justification:\n",
        "The features were selected based on their theoretical and empirical relationship with salary:\n",
        "\n",
        "STATE & Political Leaning: Geographic location and political climate influence cost of living and compensation policies\n",
        "TITLE: Job title is the primary indicator of role level and responsibility\n",
        "LIGHTCAST_SECTORS: Industry sector determines baseline compensation structure\n",
        "SOC/NAICS: Occupation classification provides standardized job categorization\n",
        "Years of Experience: Direct correlation with salary progression (if available)\n"
      ],
      "id": "d9a74725"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: train-test-split-regression\n",
        "#| code-fold: true\n",
        "\n",
        "# Split data (70/30 as per assignment requirements)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.30, random_state=42\n",
        ")\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"TRAIN/TEST SPLIT\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nTraining Set: {X_train.shape[0]:,} samples ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
        "print(f\"Test Set: {X_test.shape[0]:,} samples ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
        "print(f\"\\nSalary Distribution:\")\n",
        "print(f\"  Training Set - Mean: ${y_train.mean():,.2f}, Std: ${y_train.std():,.2f}\")\n",
        "print(f\"  Test Set - Mean: ${y_test.mean():,.2f}, Std: ${y_test.std():,.2f}\")"
      ],
      "id": "train-test-split-regression",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: random-forest-regression\n",
        "#| code-fold: true\n",
        "#| code-summary: View Random Forest code\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"MODEL 2: RANDOM FOREST REGRESSION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Train model\n",
        "rf_reg = RandomForestRegressor(\n",
        "    n_estimators=100,\n",
        "    max_depth=20,\n",
        "    min_samples_split=10,\n",
        "    min_samples_leaf=4,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "print(\"Training Random Forest model...\")\n",
        "rf_reg.fit(X_train, y_train)\n",
        "print(\"âœ“ Training complete!\")\n",
        "\n",
        "# Make predictions\n",
        "y_pred_rf = rf_reg.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
        "r2_rf = r2_score(y_test, y_pred_rf)\n",
        "mae_rf = np.mean(np.abs(y_test - y_pred_rf))\n",
        "\n",
        "print(f\"\\nðŸ“Š Model Performance:\")\n",
        "print(f\"   â€¢ RÂ² Score: {r2_rf:.4f}\")\n",
        "print(f\"     â†’ Explains {r2_rf*100:.2f}% of salary variance\")\n",
        "print(f\"   â€¢ RMSE: ${rmse_rf:,.2f}\")\n",
        "print(f\"   â€¢ MAE: ${mae_rf:,.2f}\")\n",
        "\n",
        "# Feature importance\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': feature_cols,\n",
        "    'Importance': rf_reg.feature_importances_\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "print(f\"\\nðŸ“ˆ Top 10 Most Important Features:\")\n",
        "print(importance_df.head(10).to_string(index=False))\n",
        "\n",
        "# Calculate improvement over linear regression\n",
        "improvement = ((r2_rf - r2_lin) / r2_lin) * 100 if r2_lin > 0 else 0\n",
        "print(f\"\\nðŸš€ Random Forest improves RÂ² by {improvement:.1f}% over Linear Regression\")"
      ],
      "id": "random-forest-regression",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: predictions-vs-actual\n",
        "#| code-fold: true\n",
        "\n",
        "# Sample data for visualization (performance optimization)\n",
        "sample_size = min(2000, len(y_test))\n",
        "indices = np.random.choice(len(y_test), sample_size, replace=False)\n",
        "\n",
        "comparison_results = pd.DataFrame({\n",
        "    'Actual': y_test.iloc[indices],\n",
        "    'Linear_Regression': y_pred_lin[indices],\n",
        "    'Random_Forest': y_pred_rf[indices]\n",
        "})\n",
        "\n",
        "# Create scatter plot\n",
        "fig = go.Figure()\n",
        "\n",
        "# Random Forest predictions\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=comparison_results['Actual'],\n",
        "    y=comparison_results['Random_Forest'],\n",
        "    mode='markers',\n",
        "    name='Random Forest',\n",
        "    opacity=0.6,\n",
        "    marker=dict(\n",
        "        size=5,\n",
        "        color='blue',\n",
        "        line=dict(width=0.5, color='darkblue')\n",
        "    )\n",
        "))\n",
        "\n",
        "# Linear Regression predictions\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=comparison_results['Actual'],\n",
        "    y=comparison_results['Linear_Regression'],\n",
        "    mode='markers',\n",
        "    name='Linear Regression',\n",
        "    opacity=0.6,\n",
        "    marker=dict(\n",
        "        size=5,\n",
        "        color='red',\n",
        "        line=dict(width=0.5, color='darkred')\n",
        "    )\n",
        "))\n",
        "\n",
        "# Perfect prediction line\n",
        "min_val = min(y_test.min(), y_pred_rf.min(), y_pred_lin.min())\n",
        "max_val = max(y_test.max(), y_pred_rf.max(), y_pred_lin.max())\n",
        "\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=[min_val, max_val],\n",
        "    y=[min_val, max_val],\n",
        "    mode='lines',\n",
        "    name='Perfect Prediction',\n",
        "    line=dict(color='green', dash='dash', width=2)\n",
        "))\n",
        "\n",
        "fig.update_layout(\n",
        "    title=f'Actual vs Predicted Salary - Model Comparison (n={sample_size:,})',\n",
        "    xaxis_title='Actual Salary ($)',\n",
        "    yaxis_title='Predicted Salary ($)',\n",
        "    template=\"plotly_white\",\n",
        "    height=550,\n",
        "    hovermode='closest'\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "id": "predictions-vs-actual",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: residual-analysis\n",
        "#| code-fold: true\n",
        "\n",
        "# Calculate residuals\n",
        "residuals_lin = y_test - y_pred_lin\n",
        "residuals_rf = y_test - y_pred_rf\n",
        "\n",
        "# Create residual plots\n",
        "fig = make_subplots(\n",
        "    rows=1, cols=2,\n",
        "    subplot_titles=('Linear Regression Residuals', 'Random Forest Residuals')\n",
        ")\n",
        "\n",
        "# Linear Regression residuals\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=y_pred_lin,\n",
        "        y=residuals_lin,\n",
        "        mode='markers',\n",
        "        name='Linear Reg',\n",
        "        marker=dict(size=4, color='red', opacity=0.5)\n",
        "    ),\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "# Random Forest residuals\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=y_pred_rf,\n",
        "        y=residuals_rf,\n",
        "        mode='markers',\n",
        "        name='Random Forest',\n",
        "        marker=dict(size=4, color='blue', opacity=0.5)\n",
        "    ),\n",
        "    row=1, col=2\n",
        ")\n",
        "\n",
        "# Add zero line\n",
        "for col in [1, 2]:\n",
        "    fig.add_hline(y=0, line_dash=\"dash\", line_color=\"green\", row=1, col=col)\n",
        "\n",
        "fig.update_xaxes(title_text=\"Predicted Salary ($)\", row=1, col=1)\n",
        "fig.update_xaxes(title_text=\"Predicted Salary ($)\", row=1, col=2)\n",
        "fig.update_yaxes(title_text=\"Residuals ($)\", row=1, col=1)\n",
        "fig.update_yaxes(title_text=\"Residuals ($)\", row=1, col=2)\n",
        "\n",
        "fig.update_layout(\n",
        "    height=450,\n",
        "    showlegend=False,\n",
        "    template=\"plotly_white\",\n",
        "    title_text=\"Residual Analysis - Prediction Errors\"\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "id": "residual-analysis",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}