{
  "hash": "b20a921a1e1fdcf424e10018be4b0e18",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Gender and Politics in the Job Market\"\n\nsubtitle: \"Final Report\"\nauthor:\n    - name: \"Pranathi Nagasai & Emily Sundberg\"\naffiliations:\n    - id: BU\n    - name: Boston University\n    - city: Boston\n    - state: MA\ndate: today\ndate-modified: today\ndate-format: long\nformat: \n    docx: default\n---\n\n---\n\ntitle: \"Gender Disparities in Hiring & Political Influence\"\nauthor: \"Pranathi Nagasai & Emily Sundberg\"\ndate: today\nformat:\n  html:\n    theme: cosmo\n    toc: true\n    toc-depth: 2\n    code-fold: true\n---\n\n\n\nThis research investigates the intersection of gender-based employment patterns and political geography in the United States.\n\n## Research Questions\n\n### 1. How do hiring patterns differ for men vs. women across industries?\n\nWe analyze gender representation and hiring trends across multiple sectors:\n\n- **Technology Sector**: Software development, AI/ML, data science\n- **Healthcare**: Medical professionals, administrative roles\n- **Finance**: Banking, investment, fintech\n- **Manufacturing**: Production, engineering, management\n- **Service Industries**: Retail, hospitality, education\n\n\n\n### 2. Do gender-based employment disparities vary between red and blue states?\n\nExamining state-level political affiliations and their relationship with:\n\n- **Red States (Conservative-leaning)**\n  - Gender hiring ratios\n  - Workplace policies\n  - Wage structures\n  \n- **Blue States (Liberal-leaning)**\n  - Gender hiring ratios\n  - Workplace policies\n  - Wage structures\n\n- **Swing States**: Comparative analysis of mixed political environments\n\n### 3. Are women more underrepresented in AI fields in conservative states vs. liberal states?\n\nFocused investigation on the technology sector, specifically:\n\n- **AI and Machine Learning roles**\n  - Data scientists\n  - ML engineers\n  - AI researchers\n  \n- **Women's representation comparison**:\n  - Conservative states (red states)\n  - Liberal states (blue states)\n  - National averages\n\n- **Factors analyzed**:\n  - Educational pipeline differences\n  - Company culture and policies\n  - State-level STEM initiatives\n  - Industry concentration by state\n\n### 4. How do wage gaps compare between gender and political affiliations?\n\nComprehensive wage analysis examining:\n\n- **Gender wage gaps** across:\n  - Red states\n  - Blue states\n  - Swing states\n  \n- **Industry-specific wage disparities**:\n  - Tech and AI fields\n  - Healthcare\n  - Finance\n  - Manufacturing\n  \n- **Controlling for**:\n  - Experience level\n  - Education\n  - Job title/role\n  - Company size\n  - Cost of living adjustments\n\n- **Political affiliation impact**:\n  - State minimum wage policies\n  - Equal pay legislation\n  - Workplace protection laws\n\n## Expected Findings\n\nWe expect this analysis will reveal that political geography influences gender-based employment outcomes, particularly in emerging high-wage sectors such as AI and technology. \n\n\n\n---\n\n---\ntitle: \"Gender Disparities in Hiring & Political Influence (U.S. and Global, 2024–2025)\"\nauthor:\n  - \"Pranathi Nagasai Andhe\"\n  - \"Emily Sundberg\"\ndate: today\nformat:\n  html:\n    toc: true\n    toc-depth: 3\n    number-sections: true\n    smooth-scroll: true\n  pdf:\n    toc: true\n    number-sections: true\nbibliography: references.bib\ncsl: csl/econometrica.csl\nexecute:\n  echo: false\n  warning: false\n---\n\n# Abstract\n\nWe analyze gender disparities in hiring, AI participation, and wages across U.S. industries and states, and situate these patterns in a global context. Drawing on recent federal statistics [@bls2025cps], U.S. pay-gap trackers [@aauw2025simpletruth; @iwpr2024gap], and international reports [@oecd2024algorithm; @ilo2023genai; @ilo2025exposure; @wef2025ggg], we find persistent occupational segregation, widening U.S. annual earnings gaps since 2022, and continued underrepresentation of women in AI-intensive roles. State-level disparities correlate with policy environments such as pay-transparency and salary-history bans [@aauw2025state], though industry composition and family structure are important confounders. Conservative/market-based perspectives emphasize occupational choice, hours, and career continuity as key mechanisms and warn that some transparency policies may compress wages [@aei; @heritage; @cullen2021; @cullen2023; @mas2014transparency]. We integrate both views and outline implications for job seekers selecting sectors, geographies, and employers.\n\n# Executive Summary\n\n- U.S. employment remains gender-segregated: women ≈47% of workers but overrepresented in health/education and underrepresented in construction, engineering, and many tech roles [@bls2025cps].\n- Every U.S. state has a pay gap; gaps tend to be smaller where transparency and equal-pay policies are stronger, though composition matters [@aauw2025state].\n- U.S. annual earnings gap widened after 2022 (82.7¢ in 2023; ≈80.9¢ in 2024 among full-time year-round), while hourly measures show ~85% in 2024 [@iwpr2024gap; @pew2025gap].\n- Women remain 22–30% of the global AI workforce and are more exposed to AI-driven task change in clerical/admin roles [@oecd2024algorithm; @ilo2023genai; @ilo2025exposure].\n- Globally, parity stands at 68.8% and may take ~123 years at current pace [@wef2025ggg].\n- Market-oriented analyses attribute much of the unadjusted gap to hours, occupation, and career continuity and note possible wage compression from transparency [@aei; @heritage; @cullen2021; @cullen2023; @mas2014transparency].\n- Implications: build AI-complementary skills, target transparent employers and supportive states/metros, and use posted pay bands as inputs to evidence-based negotiation.\n\n# Introduction\n\nGender continues to shape labor-market outcomes in the United States and worldwide. In 2024–2025, women's representation varies sharply across industries, wage gaps persist, and AI both creates opportunities and raises exposure risks. We examine four questions: (1) how hiring patterns differ for men and women across industries; (2) whether disparities vary between red and blue states; (3) whether women are more underrepresented in AI fields; and (4) how wage gaps compare by gender and political affiliations. We synthesize high-quality, recent statistics and research to inform job-seeker strategy.\n\n# Qualitative Research Method\n\nWe triangulate multiple sources: U.S. Bureau of Labor Statistics Current Population Survey (CPS) 2024 annual averages for occupational distributions [@bls2025cps]; AAUW 2025 national and state pay-gap indicators [@aauw2025simpletruth; @aauw2025state]; IWPR 2024 fact sheets on annual earnings gaps [@iwpr2024gap]; Pew Research Center 2025 hourly pay-gap analysis [@pew2025gap]; OECD 2024 policy brief on AI and women [@oecd2024algorithm]; International Labour Organization reports on generative-AI exposure (2023; 2025 update) [@ilo2023genai; @ilo2025exposure]; and the WEF 2025 Global Gender Gap Report [@wef2025ggg]. To incorporate conservative/market perspectives, we review AEI and Heritage commentary [@aei; @heritage] and research on equilibrium effects of pay transparency [@cullen2021; @cullen2023; @mas2014transparency].\n\n# Hiring Patterns Across Industries (U.S. and Global)\n\nU.S. employment remains gender-segregated. CPS 2024 annual averages indicate women comprise roughly 47% of total employment but are more concentrated in health care, education, and service roles, with lower shares in construction, engineering, and portions of tech [@bls2025cps]. Internationally, the World Economic Forum (2025) estimates overall global gender parity at 68.8%, with economic participation parity at about 60–61%, implying persistent cross-country segmentation [@wef2025ggg]. Market-oriented analyses argue that part of observed differences in outcomes reflect hours worked, occupation mix, and career continuity rather than like-for-like pay differences [@aei; @heritage].\n\n# State Politics and Gender Disparities (Red vs. Blue)\n\nAAUW's 2025 analysis shows that every U.S. state has a gender pay gap, with substantial dispersion across states [@aauw2025state]. Cross-state differences correlate with policy adoption such as salary-history bans and pay-transparency requirements, which are more prevalent in many blue states [@aauw2025state]. However, composition matters: industry mix (e.g., energy and construction), unionization, urbanization, and childcare access vary across states and can generate red–blue patterns without ideology being the sole driver. Earlier peer-reviewed work associates state liberalism with narrower gaps, but causality remains difficult to establish [@maume2015state]. Recent reporting suggests that post-pandemic return-to-office mandates have reduced flexibility and may contribute to widening national gaps, though these effects likely differ by state and sector [@washingtonpost2025rto].\n\n# Women in AI Fields (U.S. & Global) and Political Context\n\nWomen remain underrepresented in AI and tech roles. The OECD documents lower female representation in AI-exposed professional occupations and constrained access to AI tools [@oecd2024algorithm]. The ILO shows that clerical and administrative tasks—female-heavy—are highly exposed to generative-AI transformation in high-income countries; a 2025 refinement confirms the asymmetric exposure [@ilo2023genai; @ilo2025exposure]. Direct state-by-state measures of female AI participation are limited. It is therefore premature to assert causality from political ideology to AI underrepresentation without merging employer-level AI job postings and hires with state policy and industry controls. Nonetheless, differences in STEM pipelines, childcare, higher education, and transparency regimes plausibly contribute to cross-state variation [@ilo2023genai; @ilo2025exposure; @oecd2024algorithm].\n\n# Wage Gaps and Political Affiliation\n\nOn annual full-time, year-round earnings, IWPR reports a deterioration from 2022 to 2023 (82.7¢) and news coverage indicates about 80.9¢ in 2024—the lowest since 2016 [@iwpr2024gap; @newsweek2025gap]. By contrast, Pew Research Center's hourly series shows women earned about 85% of men's hourly pay in 2024 when combining full- and part-time workers [@pew2025gap]. Adjusted gaps shrink after controlling for occupation, hours, and experience but do not disappear [@aei; @pew2025gap]. Policy can narrow gaps: pay-transparency laws are associated with smaller within-firm gaps but may compress overall wages or slow wage growth according to equilibrium analyses [@cullen2021; @cullen2023; @mas2014transparency].\n\n# Implications for Job Seekers (2025)\n\n- **Sector choice:** Target underrepresented, higher-growth fields such as data, AI, and engineering while building verifiable skills, certifications, and portfolios [@bls2025cps; @oecd2024algorithm].\n- **Geography:** Favor states and metros with pay-transparency requirements and supportive care infrastructure while benchmarking offers with state snapshots [@aauw2025state].\n- **AI resilience:** Develop AI-complementary skills to hedge exposure in clerical/admin roles and to compete for AI-adjacent, higher-pay tracks [@ilo2023genai; @oecd2024algorithm].\n- **Employer screening:** Prefer organizations with posted pay bands, career-progression transparency, and flexible/hybrid policies as RTO mandates may widen disparities [@washingtonpost2025rto].\n- **Negotiation:** Use posted ranges as inputs, not anchors, and negotiate based on documented contributions; be aware of transparency's potential compression effects [@cullen2021; @cullen2023; @mas2014transparency].\n\n# Limitations\n\nCausal attribution of political ideology to gender disparities is challenging due to confounding by industry mix, demographics, and local cost structures. AI participation statistics with state-gender granularity remain sparse. International comparisons depend on differing definitions of occupations, pay, and employment. Transparency policy effects vary by market and occupation; equilibrium responses may offset some intended benefits.\n\n# Conclusion\n\nGender disparities in hiring, AI participation, and pay persist across the U.S. and globally. State policies and employer practices shape observed gaps, but composition and choice also matter. A pragmatic job-search strategy in 2025 combines sector targeting, AI-adjacent upskilling, careful geography selection, and screening for transparent, flexible employers. Continuous measurement using CPS updates, AAUW/IWPR dashboards, and international benchmarks will be essential for tracking progress.\n\n---\n\ntitle: \"Data Cleaning\"\nformat:\n  html:\n    code-overflow: wrap\n    code-fold: true\n    toc : false\nexecute:\n  echo: true\n  eval: true\n  freeze: auto\n---\n\n## Load the dataset\n\nThis code initializes a PySpark environment to load and explore a dataset of job postings. It begins by importing and starting a Spark session named \"`JobPostingsAnalysis`\", then reads a CSV file (`lightcast_job_postings.csv`) into a Spark DataFrame with headers, schema inference, and support for multi-line fields. The DataFrame is registered as a temporary SQL view called \"`job_postings`\" to enable SQL-style queries. Finally, it performs a basic diagnostic check by printing the schema and previewing the first five rows of data—steps that are intended for local debugging and should be commented out when rendering the final submission.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport plotly.express as px\nimport plotly.io as pio\nfrom pyspark.sql import SparkSession\nimport re\nimport numpy as np\nimport plotly.graph_objects as go\nfrom pyspark.sql.functions import col, split, explode, regexp_replace, transform, when\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.functions import col, monotonically_increasing_id\n\nnp.random.seed(42)\n\npio.renderers.default = \"notebook\"\n\nspark = SparkSession.builder.appName(\"LightcastData\").getOrCreate()\n\njobs_df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"multiLine\",\"true\").option(\"escape\", \"\\\"\").csv(\"./data/lightcast_job_postings.csv\")\njobs_df.createOrReplaceTempView(\"job_postings\")\n\nelections_df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"multiLine\",\"true\").option(\"escape\", \"\\\"\").csv(\"./data/2024_election_results.csv\")\nelections_df.createOrReplaceTempView(\"election_results\")\n\n#print(\"---This is Diagnostic check, No need to print it in the final doc---\")\n\n#df.printSchema() # comment this line when rendering the submission\n#jobs_df.show(5)\n#elections_df.show(5)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nSetting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n25/10/16 01:58:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n25/10/16 01:58:51 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n\r[Stage 1:>                                                          (0 + 1) / 1]\r\r                                                                                \r25/10/16 01:59:06 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n```\n:::\n:::\n\n\n## Data Cleaning\n\nThe following code cleans and standardizes the job postings dataset — ensuring proper data types, filling missing salaries, removing duplicates, categorizing remote types, and dropping overly sparse columns — to produce a clean, analysis-ready DataFrame.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\n# casting corrected variable type\njobs_df = jobs_df.withColumn(\"SALARY_FROM\", col (\"SALARY_FROM\").cast(\"float\"))\\\n  .withColumn(\"SALARY_TO\", col(\"SALARY_TO\").cast(\"float\")) \\\n  .withColumn(\"MAX_YEARS_EXPERIENCE\", col(\"MAX_YEARS_EXPERIENCE\").cast(\"float\"))\\\n  .withColumn(\"MIN_YEARS_EXPERIENCE\", col(\"MIN_YEARS_EXPERIENCE\").cast(\"float\"))\\\n  .withColumn(\"SALARY\", col(\"SALARY\").cast(\"float\"))\n\n# Clean Up Columns\njobs_df = jobs_df.withColumn(\"EDUCATION_LEVELS_NAME\", regexp_replace(col(\"EDUCATION_LEVELS_NAME\"), \"[\\n\\r]\", \"\"))\njobs_df = jobs_df.withColumn(\"SOURCE_TYPES\", regexp_replace(col(\"SOURCE_TYPES\"), \"[\\n\\r]\", \"\"))\njobs_df = jobs_df.withColumn(\"SOURCES\", regexp_replace(col(\"SOURCES\"), \"[\\n\\r]\", \"\"))\njobs_df = jobs_df.withColumn(\"SKILLS\", regexp_replace(col(\"SKILLS\"), \"[\\n\\r]\", \"\"))\njobs_df = jobs_df.withColumn(\"SKILLS_NAME\", regexp_replace(col(\"SKILLS_NAME\"), \"[\\n\\r]\", \"\"))\njobs_df = jobs_df.withColumn(\"SPECIALIZED_SKILLS_NAME\", regexp_replace(col(\"SPECIALIZED_SKILLS_NAME\"), \"[\\n\\r]\", \"\"))\njobs_df = jobs_df.withColumn(\"CERTIFICATIONS_NAME\", regexp_replace(col(\"CERTIFICATIONS_NAME\"), \"[\\n\\r]\", \"\"))\njobs_df = jobs_df.withColumn(\"COMMON_SKILLS_NAME\", regexp_replace(col(\"COMMON_SKILLS_NAME\"), \"[\\n\\r]\", \"\"))\njobs_df = jobs_df.withColumn(\"SOFTWARE_SKILLS_NAME\", regexp_replace(col(\"SOFTWARE_SKILLS_NAME\"), \"[\\n\\r]\", \"\"))\njobs_df = jobs_df.withColumn(\"CIP6_NAME\", regexp_replace(col(\"CIP6_NAME\"), \"[\\n\\r]\", \"\"))\njobs_df = jobs_df.withColumn(\"CIP4_NAME\", regexp_replace(col(\"CIP4_NAME\"), \"[\\n\\r]\", \"\"))\njobs_df = jobs_df.withColumn(\"CIP2_NAME\", regexp_replace(col(\"CIP2_NAME\"), \"[\\n\\r]\", \"\"))\n\n\n# Compute and impute Median Salary\ndef compute_median(sdf, col_name):\n  q = sdf.approxQuantile(col_name, [0.5], 0.01)\n  return q[0] if q else None\n\n\nmedian_from = compute_median(jobs_df, \"SALARY_FROM\")\nmedian_to = compute_median(jobs_df, \"SALARY_TO\")\nmedian_salary = compute_median(jobs_df, \"SALARY\")\n\nprint(\"Medians:\", median_from, median_to, median_salary)\n\njobs_df = jobs_df.fillna({\n  \"SALARY_FROM\": median_from,\n  \"SALARY_TO\": median_to,\n  \"SALARY\": median_salary\n})\n\nfrom pyspark.sql.functions import col\njobs_df = jobs_df.withColumn(\n    \"MIDPOINT_SALARY\",\n    (col(\"SALARY_TO\") + col(\"SALARY_FROM\")) / 2\n)\n\n# Dropping unnecessary columns\ncolumns_to_drop = [\n    \"ID\", \"URL\", \"ACTIVE_URLS\", \"DUPLICATES\", \"LAST_UPDATED_TIMESTAMP\",\"STATE\",\"COUNTY_OUTGOING\",\"COUNTY_INCOMMING\",\"MSA_OUTGOING\",\"MSA_INCOMING\",\n    \"NAICS2\", \"NAICS3\", \"NAICS4\", \"NAICS5\", \"NAICS6\", \"ONET\",\"ONET_2019\",\"CIP6\",\"CIP4\",\"CIP2\",\"SOC_2021_2\",\"SOC_2021_3\",\"SOC_2021_4\",\"SOC_2021_5\",\"SOC_2\", \"SOC_3\", \"SOC_4\",\"SOC_5\", \"NAICS_2022_2\",\"NAICS_2022_3\",\"NAICS_2022_4\",\"NAICS_2022_5\",\"NAICS_2022_6\",\"CITY\",\"COUNTY\",\"MSA\",\"COUNTY_INCOMING\"\n]\njobs_df = jobs_df.drop(*columns_to_drop)\n\n# configuring remote work groups\nfrom pyspark.sql.functions import when, col, trim\n\njobs_df = jobs_df.withColumn(\"REMOTE_GROUP\",\n  when(trim(col(\"REMOTE_TYPE_NAME\"))== \"Remote\", \"Remote\")\n  .when(trim(col(\"REMOTE_TYPE_NAME\"))== \"Hybrid Remote\", \"Hybrid\")\n  .when(trim(col(\"REMOTE_TYPE_NAME\"))== \"Not Remote\", \"Onsite\")\n  .when(col(\"REMOTE_TYPE_NAME\").isNull(), \"Onsite\")\n  .otherwise(\"Onsite\")\n)\n\n# dropping any duplicate postings\njobs_df = jobs_df.dropDuplicates([\"TITLE\", \"COMPANY\", \"LOCATION\", \"POSTED\"])\n\n# handling missing data\nfrom pyspark.sql.functions import col, when, sum as spark_sum\n\ntotal_rows = jobs_df.count()\nmissing_threshold = total_rows * 0.5\nnull_counts = jobs_df.select([\n    (spark_sum(col(c).isNull().cast(\"int\"))).alias(c) for c in jobs_df.columns\n]).collect()[0].asDict()\ncolumns_to_keep = [c for c, nulls in null_counts.items() if nulls <= missing_threshold or c == \"SALARY\"]\njobs_df = jobs_df.select(columns_to_keep)\n\n#jobs_df.show(15)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\r[Stage 4:>                                                          (0 + 1) / 1]\r\r                                                                                \r\r[Stage 5:>                                                          (0 + 1) / 1]\r\r                                                                                \r\r[Stage 6:>                                                          (0 + 1) / 1]\r\r                                                                                \r\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nMedians: 87295.0 130042.0 115024.0\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\r[Stage 7:>                                                          (0 + 1) / 1]\r\r                                                                                \r\r[Stage 13:>                                                         (0 + 1) / 1]\r\r[Stage 15:>                                                         (0 + 2) / 6]\r\r[Stage 15:=========>                                                (1 + 2) / 6]\r\r[Stage 15:===================>                                      (2 + 2) / 6]\r\r[Stage 15:=============================>                            (3 + 2) / 6]\r\r[Stage 15:======================================>                   (4 + 2) / 6]\r\r[Stage 15:================================================>         (5 + 1) / 6]\r\r                                                                                \r\n```\n:::\n:::\n\n\nThis part of the script joins in another data frame that has the 2024 presidential election results by state. This allows us to use the states' political affiliation as an attribute of the job posting. \n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nfrom pyspark.sql import functions as F\n\njobs_df = jobs_df.withColumn(\"STATE_ABBREVIATION\", F.trim(F.split(jobs_df[\"COUNTY_NAME\"], \",\").getItem(1)))\n\njobs_alias = jobs_df.alias(\"jobs\")\nelections_alias = elections_df.alias(\"elections\")\n\njobs_df = jobs_alias.join(\n    elections_alias,\n    F.col(\"jobs.STATE_ABBREVIATION\") == F.col(\"elections.STATE\"),\n    \"left\"\n)\njobs_df = jobs_df.drop(F.col(\"elections.STATE\"))\n\njobs_df = jobs_df.withColumnRenamed(\"Affiliation\", \"AFFILIATION\")\n\n#jobs_df.show(15)\n```\n:::\n\n\nNow, this script selects only the columns we want to look at specifically \n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nselected_df = jobs_df.select(\n  \"EDUCATION_LEVELS_NAME\",\n  \"MIN_EDULEVELS_NAME\",\n  \"EMPLOYMENT_TYPE_NAME\",\n  \"MIN_YEARS_EXPERIENCE\",\n  \"SALARY_TO\",\n  \"SALARY_FROM\",\n  \"SALARY\",\n  \"CITY_NAME\",\n  \"MSA_NAME\",\n  \"STATE_NAME\",\n  \"NAICS2_NAME\",\n  \"NAICS3_NAME\",\n  \"NAICS4_NAME\",\n  \"NAICS5_NAME\",\n  \"NAICS6_NAME\",\n  \"SKILLS_NAME\",\n  \"SPECIALIZED_SKILLS_NAME\",\n  \"CERTIFICATIONS_NAME\",\n  \"COMMON_SKILLS_NAME\",\n  \"SOFTWARE_SKILLS_NAME\",\n  \"ONET_NAME\",\n  \"LOT_CAREER_AREA_NAME\",\n  \"LOT_OCCUPATION_NAME\",\n  \"LOT_SPECIALIZED_OCCUPATION_NAME\",\n  \"LOT_OCCUPATION_GROUP_NAME\",\n  \"LOT_V6_SPECIALIZED_OCCUPATION_NAME\",\n  \"LOT_V6_OCCUPATION_NAME\",\n  \"LOT_V6_OCCUPATION_GROUP_NAME\",\n  \"LOT_V6_CAREER_AREA_NAME\",\n  \"SOC_2_NAME\",\n  \"SOC_3_NAME\",\n  \"SOC_4_NAME\",\n  \"SOC_5_NAME\",\n  \"REMOTE_GROUP\",\n  \"STATE_ABBREVIATION\",\n  \"AFFILIATION\",\n  \"MIDPOINT_SALARY\"\n)\n```\n:::\n\n\nOnce we have the columns we want to look at, we create a heat map to show us the remaining missing values. We have already dealt with a lot of missing values earlier, but this will help us visualize what is left. \n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nimport pandas as pd\nfrom pyspark.sql.functions import col, sum as spark_sum, when, trim, length\nimport hvplot.pandas\n\ndf_sample_viz = selected_df.select(\n  \"MIN_YEARS_EXPERIENCE\",\n  \"SALARY\",\n  \"MSA_NAME\",\n  \"NAICS5_NAME\"\n)\n\ndf_sample = df_sample_viz.sample(fraction = .15, seed = 42).toPandas()\n\nmissing_mask = df_sample.isnull()\n\nmissing_long = (\n  missing_mask.reset_index()\n  .melt(id_vars = \"index\", var_name = \"column\", value_name = \"is_missing\")\n)\n\nmissing_long[\"is_missing\"] = missing_long[\"is_missing\"].astype(int)\n\nmissing = missing_long.hvplot.heatmap(\n  x=\"column\",\n  y=\"index\",\n  C = \"is_missing\",\n  cmap = \"Blues\",\n  width = 900,\n  height = 500,\n  title = \"Heatmap of Missing Values (15%)\"\n).opts(xrotation=45)\n\nhvplot.save(missing, './output/missing_heatmap.html')\n```\n\n::: {.cell-output .cell-output-display}\n```\nUnable to display output for mime type(s): text/html\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```\nUnable to display output for mime type(s): application/javascript, application/vnd.holoviews_load.v0+json\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```\nUnable to display output for mime type(s): application/javascript, application/vnd.holoviews_load.v0+json\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```\nUnable to display output for mime type(s): application/vnd.holoviews_exec.v0+json, text/html\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\r[Stage 20:>                                                         (0 + 1) / 1]\r\r[Stage 22:>                                                         (0 + 2) / 2]\r\r                                                                                \r\n```\n:::\n:::\n\n\n```{=html}\n<iframe width=\"900\" height=\"650\" src=\"./output/missing_heatmap.html\" title=\"Missing Values Heatmap\"></iframe>\n```\n\nAs you can see above, the missing values are mainly in the columns for minimum years of experience, and MSA name. The following script cleans up some of the column values and replaces missing values with an appropriate substitute such as 0 or \"unknown\".\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nfrom pyspark.sql.functions import countDistinct\n\nselected_df.select([\n  countDistinct(c).alias(c+\"_nunique\")\n  for c in selected_df.columns\n]).show(truncate=False)\n\n# Education Levels\n\nselected_df = selected_df.withColumn(\n  \"EDUCATION_LEVELS_NAME\",\n    when(col(\"EDUCATION_LEVELS_NAME\").isNull(), \"No Education Listed\")\n    .otherwise(col(\"EDUCATION_LEVELS_NAME\"))\n)\n\n# Min Edu Levels\n\nselected_df = selected_df.withColumn(\n  \"MIN_EDULEVELS_NAME\",\n    when(col(\"MIN_EDULEVELS_NAME\").isNull(), \"No Education Listed\")\n    .otherwise(col(\"MIN_EDULEVELS_NAME\"))\n)\n\n# Employment Type Name\n\nselected_df = selected_df.withColumn(\n  \"EMPLOYMENT_TYPE_NAME\",\n    when(col(\"EMPLOYMENT_TYPE_NAME\") == \"Part-time / full-time\",\"Flexible\")\n    .when(col(\"EMPLOYMENT_TYPE_NAME\") == \"Part-time (â‰¤ 32 hours)\",\"Part-Time\")\n    .when(col(\"EMPLOYMENT_TYPE_NAME\") == \"Full-time (> 32 hours)\",\"Full-Time\")\n    .when(col(\"EMPLOYMENT_TYPE_NAME\").isNull(), \"Full-Time\")\n    .otherwise(col(\"EMPLOYMENT_TYPE_NAME\"))\n)\n\n# Min Years Experience\nselected_df = selected_df.withColumn(\n    \"MIN_YEARS_EXPERIENCE\",\n    when(col(\"MIN_YEARS_EXPERIENCE\").isNull(), 0)\n    .otherwise(col(\"MIN_YEARS_EXPERIENCE\"))\n)\n\n# Salary to\nselected_df = selected_df.withColumn(\n    \"SALARY_TO\",\n    when(col(\"SALARY_TO\").isNull(), median_to)\n    .otherwise(col(\"SALARY_TO\"))\n)\n\n# Salary from\nselected_df = selected_df.withColumn(\n    \"SALARY_FROM\",\n    when(col(\"SALARY_FROM\").isNull(), median_from)\n    .otherwise(col(\"SALARY_FROM\"))\n)\n\n# Salary \nselected_df = selected_df.withColumn(\n    \"SALARY\",\n    when(col(\"SALARY\").isNull(), median_salary)\n    .otherwise(col(\"SALARY\"))\n)\n\n# City Name\nselected_df = selected_df.withColumn(\n  \"CITY_NAME\",\n    when(col(\"CITY_NAME\").isNull(), \"Unknown\")\n    .otherwise(col(\"CITY_NAME\"))\n)\n\n# MSA Name\nselected_df = selected_df.withColumn(\n  \"MSA_NAME\",\n    when(col(\"MSA_NAME\").isNull(), \"Unknown\")\n    .otherwise(col(\"MSA_NAME\"))\n)\n\n# State Name\nselected_df = selected_df.withColumn(\n  \"STATE_NAME\",\n    when(col(\"STATE_NAME\").isNull(), \"Unknown\")\n    .otherwise(col(\"STATE_NAME\"))\n)\n\n# NAICS2_NAME \nselected_df = selected_df.withColumn(\n  \"NAICS2_NAME\",\n    when(col(\"NAICS2_NAME\").isNull(), \"Unknown\")\n    .otherwise(col(\"NAICS2_NAME\"))\n)\n\n# NAICS3_NAME \nselected_df = selected_df.withColumn(\n  \"NAICS3_NAME\",\n    when(col(\"NAICS3_NAME\").isNull(), \"Unknown\")\n    .otherwise(col(\"NAICS3_NAME\"))\n)\n\n# NAICS4_NAME \nselected_df = selected_df.withColumn(\n  \"NAICS4_NAME\",\n    when(col(\"NAICS4_NAME\").isNull(), \"Unknown\")\n    .otherwise(col(\"NAICS4_NAME\"))\n)\n\n# NAICS5_NAME \nselected_df = selected_df.withColumn(\n  \"NAICS5_NAME\",\n    when(col(\"NAICS5_NAME\").isNull(), \"Unknown\")\n    .otherwise(col(\"NAICS5_NAME\"))\n)\n\n# NAICS6_NAME \nselected_df = selected_df.withColumn(\n  \"NAICS6_NAME\",\n    when(col(\"NAICS6_NAME\").isNull(), \"Unknown\")\n    .otherwise(col(\"NAICS6_NAME\"))\n)\n\n#STATE ABBREVIATION\nselected_df = selected_df.withColumn(\n  \"STATE_ABBREVIATION\",\n    when(col(\"STATE_ABBREVIATION\").isNull(), \"Unknown\")\n    .otherwise(col(\"STATE_ABBREVIATION\"))\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\r[Stage 24:>                                                         (0 + 1) / 1]\r\r[Stage 26:>                                                         (0 + 2) / 2]\r\r[Stage 26:=============================>                            (1 + 1) / 2]\r\r[Stage 29:>                                                         (0 + 2) / 2]\r\r                                                                                \r\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n+-----------------------------+--------------------------+----------------------------+----------------------------+-----------------+-------------------+--------------+-----------------+----------------+------------------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------------------+---------------------------+--------------------------+----------------------------+-----------------+----------------------------+---------------------------+---------------------------------------+---------------------------------+------------------------------------------+------------------------------+------------------------------------+-------------------------------+------------------+------------------+------------------+------------------+--------------------+--------------------------+-------------------+-----------------------+\n|EDUCATION_LEVELS_NAME_nunique|MIN_EDULEVELS_NAME_nunique|EMPLOYMENT_TYPE_NAME_nunique|MIN_YEARS_EXPERIENCE_nunique|SALARY_TO_nunique|SALARY_FROM_nunique|SALARY_nunique|CITY_NAME_nunique|MSA_NAME_nunique|STATE_NAME_nunique|NAICS2_NAME_nunique|NAICS3_NAME_nunique|NAICS4_NAME_nunique|NAICS5_NAME_nunique|NAICS6_NAME_nunique|SKILLS_NAME_nunique|SPECIALIZED_SKILLS_NAME_nunique|CERTIFICATIONS_NAME_nunique|COMMON_SKILLS_NAME_nunique|SOFTWARE_SKILLS_NAME_nunique|ONET_NAME_nunique|LOT_CAREER_AREA_NAME_nunique|LOT_OCCUPATION_NAME_nunique|LOT_SPECIALIZED_OCCUPATION_NAME_nunique|LOT_OCCUPATION_GROUP_NAME_nunique|LOT_V6_SPECIALIZED_OCCUPATION_NAME_nunique|LOT_V6_OCCUPATION_NAME_nunique|LOT_V6_OCCUPATION_GROUP_NAME_nunique|LOT_V6_CAREER_AREA_NAME_nunique|SOC_2_NAME_nunique|SOC_3_NAME_nunique|SOC_4_NAME_nunique|SOC_5_NAME_nunique|REMOTE_GROUP_nunique|STATE_ABBREVIATION_nunique|AFFILIATION_nunique|MIDPOINT_SALARY_nunique|\n+-----------------------------+--------------------------+----------------------------+----------------------------+-----------------+-------------------+--------------+-----------------+----------------+------------------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------------------+---------------------------+--------------------------+----------------------------+-----------------+----------------------------+---------------------------+---------------------------------------+---------------------------------+------------------------------------------+------------------------------+------------------------------------+-------------------------------+------------------+------------------+------------------+------------------+--------------------+--------------------------+-------------------+-----------------------+\n|29                           |6                         |3                           |16                          |4429             |4143               |5986          |3840             |653             |51                |21                 |97                 |294                |600                |814                |43269              |40734                          |1571                       |29170                     |22180                       |1                |4                           |6                          |11                                     |6                                |11                                        |6                             |6                                   |4                              |1                 |1                 |1                 |1                 |3                   |51                        |2                  |5346                   |\n+-----------------------------+--------------------------+----------------------------+----------------------------+-----------------+-------------------+--------------+-----------------+----------------+------------------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------------------+---------------------------+--------------------------+----------------------------+-----------------+----------------------------+---------------------------+---------------------------------------+---------------------------------+------------------------------------------+------------------------------+------------------------------------+-------------------------------+------------------+------------------+------------------+------------------+--------------------+--------------------------+-------------------+-----------------------+\n\n```\n:::\n:::\n\n\nFinally, we have a clean dataset so we will convert it to a pandas dataframe and save it a csv.\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\npdf = selected_df.toPandas()\n\npdf.to_csv(\"./data/lightcast_cleaned.csv\", index=False)\n\npdf.head(15)\n\nprint(\"Data Cleaning Complete. Rows retained:\", len(pdf))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\r[Stage 35:>                                                         (0 + 1) / 1]\r\r[Stage 37:>                                                         (0 + 2) / 2]\r\r                                                                                \r\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nData Cleaning Complete. Rows retained: 69198\n```\n:::\n:::\n\n\n---\ntitle: \"Exploratory Data Analysis\"\nformat:\n  html:\n    code-overflow: wrap\n    code-fold: true\n    toc: false\n\nexecute:\n  echo: false\n  eval: true\n  output: true\n  freeze: auto\n---\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nimport pandas as pd\nimport plotly.express as px\nimport plotly.io as pio\nfrom pyspark.sql import SparkSession\nimport re\nimport numpy as np\nimport plotly.graph_objects as go\nfrom pyspark.sql.functions import col, split, explode, regexp_replace, transform, when\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.functions import col, monotonically_increasing_id\n\nnp.random.seed(42)\n\npio.renderers.default = \"notebook\"\n\nspark = SparkSession.builder.appName(\"LightcastCleanedData\").getOrCreate()\n\neda = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"multiLine\",\"true\").option(\"escape\", \"\\\"\").csv(\"./data/lightcast_cleaned.csv\")\n\neda.show(15)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n25/10/16 02:01:23 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n\r[Stage 39:>                                                         (0 + 1) / 1]\r\r                                                                                \r\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n+---------------------+-------------------+--------------------+--------------------+---------+-----------+--------+-------------------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+-------------------+------------------+--------------------+--------------------+--------------------+--------------------+-------------------------------+-------------------------+----------------------------------+----------------------+----------------------------+-----------------------+--------------------+--------------------+---------------+---------------+------------+------------------+-----------+---------------+\n|EDUCATION_LEVELS_NAME| MIN_EDULEVELS_NAME|EMPLOYMENT_TYPE_NAME|MIN_YEARS_EXPERIENCE|SALARY_TO|SALARY_FROM|  SALARY|          CITY_NAME|            MSA_NAME|STATE_NAME|         NAICS2_NAME|         NAICS3_NAME|         NAICS4_NAME|         NAICS5_NAME|         NAICS6_NAME|         SKILLS_NAME|SPECIALIZED_SKILLS_NAME|CERTIFICATIONS_NAME|COMMON_SKILLS_NAME|SOFTWARE_SKILLS_NAME|           ONET_NAME|LOT_CAREER_AREA_NAME| LOT_OCCUPATION_NAME|LOT_SPECIALIZED_OCCUPATION_NAME|LOT_OCCUPATION_GROUP_NAME|LOT_V6_SPECIALIZED_OCCUPATION_NAME|LOT_V6_OCCUPATION_NAME|LOT_V6_OCCUPATION_GROUP_NAME|LOT_V6_CAREER_AREA_NAME|          SOC_2_NAME|          SOC_3_NAME|     SOC_4_NAME|     SOC_5_NAME|REMOTE_GROUP|STATE_ABBREVIATION|AFFILIATION|MIDPOINT_SALARY|\n+---------------------+-------------------+--------------------+--------------------+---------+-----------+--------+-------------------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+-------------------+------------------+--------------------+--------------------+--------------------+--------------------+-------------------------------+-------------------------+----------------------------------+----------------------+----------------------------+-----------------------+--------------------+--------------------+---------------+---------------+------------+------------------+-----------+---------------+\n|  No Education Listed|No Education Listed|           Full-Time|                 0.0| 130042.0|    87295.0|115024.0|            Unknown|             Unknown|   Unknown|             Unknown|             Unknown|             Unknown|             Unknown|             Unknown|                NULL|                   NULL|               NULL|              NULL|                NULL|                NULL|                NULL|                NULL|                           NULL|                     NULL|                              NULL|                  NULL|                        NULL|                   NULL|                NULL|                NULL|           NULL|           NULL|      Onsite|           Unknown|       NULL|       108668.5|\n|  No Education Listed|No Education Listed|           Full-Time|                 0.0| 130042.0|    87295.0|115024.0|            Unknown|             Unknown|   Unknown|             Unknown|             Unknown|             Unknown|             Unknown|             Unknown|                NULL|                   NULL|               NULL|              NULL|                NULL|                NULL|                NULL|                NULL|                           NULL|                     NULL|                              NULL|                  NULL|                        NULL|                   NULL|                NULL|                NULL|           NULL|           NULL|      Onsite|           Unknown|       NULL|       108668.5|\n|  No Education Listed|No Education Listed|           Full-Time|                 0.0| 130042.0|    87295.0|115024.0|            Unknown|             Unknown|   Unknown|             Unknown|             Unknown|             Unknown|             Unknown|             Unknown|                NULL|                   NULL|               NULL|              NULL|                NULL|                NULL|                NULL|                NULL|                           NULL|                     NULL|                              NULL|                  NULL|                        NULL|                   NULL|                NULL|                NULL|           NULL|           NULL|      Onsite|           Unknown|       NULL|       108668.5|\n|  No Education Listed|No Education Listed|           Full-Time|                 0.0| 130042.0|    87295.0|115024.0|            Unknown|             Unknown|   Unknown|             Unknown|             Unknown|             Unknown|             Unknown|             Unknown|                NULL|                   NULL|               NULL|              NULL|                NULL|                NULL|                NULL|                NULL|                           NULL|                     NULL|                              NULL|                  NULL|                        NULL|                   NULL|                NULL|                NULL|           NULL|           NULL|      Onsite|           Unknown|       NULL|       108668.5|\n|  No Education Listed|No Education Listed|           Full-Time|                 0.0| 130042.0|    87295.0|115024.0|            Unknown|             Unknown|   Unknown|             Unknown|             Unknown|             Unknown|             Unknown|             Unknown|                NULL|                   NULL|               NULL|              NULL|                NULL|                NULL|                NULL|                NULL|                           NULL|                     NULL|                              NULL|                  NULL|                        NULL|                   NULL|                NULL|                NULL|           NULL|           NULL|      Onsite|           Unknown|       NULL|       108668.5|\n|  No Education Listed|No Education Listed|           Full-Time|                 0.0| 130042.0|    87295.0|115024.0|            Unknown|             Unknown|   Unknown|             Unknown|             Unknown|             Unknown|             Unknown|             Unknown|                NULL|                   NULL|               NULL|              NULL|                NULL|                NULL|                NULL|                NULL|                           NULL|                     NULL|                              NULL|                  NULL|                        NULL|                   NULL|                NULL|                NULL|           NULL|           NULL|      Onsite|           Unknown|       NULL|       108668.5|\n|  No Education Listed|No Education Listed|           Full-Time|                 0.0| 130042.0|    87295.0|115024.0|            Unknown|             Unknown|   Unknown|             Unknown|             Unknown|             Unknown|             Unknown|             Unknown|                NULL|                   NULL|               NULL|              NULL|                NULL|                NULL|                NULL|                NULL|                           NULL|                     NULL|                              NULL|                  NULL|                        NULL|                   NULL|                NULL|                NULL|           NULL|           NULL|      Onsite|           Unknown|       NULL|       108668.5|\n|  No Education Listed|No Education Listed|           Full-Time|                 0.0| 130042.0|    87295.0|115024.0|            Unknown|             Unknown|   Unknown|             Unknown|             Unknown|             Unknown|             Unknown|             Unknown|                NULL|                   NULL|               NULL|              NULL|                NULL|                NULL|                NULL|                NULL|                           NULL|                     NULL|                              NULL|                  NULL|                        NULL|                   NULL|                NULL|                NULL|           NULL|           NULL|      Onsite|           Unknown|       NULL|       108668.5|\n|  No Education Listed|No Education Listed|           Full-Time|                 0.0| 130042.0|    87295.0|115024.0|            Unknown|             Unknown|   Unknown|             Unknown|             Unknown|             Unknown|             Unknown|             Unknown|                NULL|                   NULL|               NULL|              NULL|                NULL|                NULL|                NULL|                NULL|                           NULL|                     NULL|                              NULL|                  NULL|                        NULL|                   NULL|                NULL|                NULL|           NULL|           NULL|      Onsite|           Unknown|       NULL|       108668.5|\n|  No Education Listed|No Education Listed|           Full-Time|                 0.0| 130042.0|    87295.0|115024.0|            Unknown|             Unknown|   Unknown|             Unknown|             Unknown|             Unknown|             Unknown|             Unknown|                NULL|                   NULL|               NULL|              NULL|                NULL|                NULL|                NULL|                NULL|                           NULL|                     NULL|                              NULL|                  NULL|                        NULL|                   NULL|                NULL|                NULL|           NULL|           NULL|      Onsite|           Unknown|       NULL|       108668.5|\n| [  \"No Education ...|No Education Listed|           Full-Time|                 0.0| 130042.0|    87295.0|115024.0| [Unknown City], UT|             Unknown|      Utah|Unclassified Indu...|Unclassified Indu...|Unclassified Indu...|Unclassified Indu...|Unclassified Indu...|    [  \"Positivity\"]|                     []|                 []|  [  \"Positivity\"]|                  []|Business Intellig...|Information Techn...|Business Intellig...|           Oracle Consultant...|     Business Intellig...|              Oracle Consultant...|  Business Intellig...|        Business Intellig...|   Information Techn...|Computer and Math...|Mathematical Scie...|Data Scientists|Data Scientists|      Onsite|                UT|        Red|       108668.5|\n| [  \"No Education ...|No Education Listed|           Full-Time|                 0.0| 130042.0|    87295.0|115024.0| [Unknown City], TX|             Unknown|     Texas|Unclassified Indu...|Unclassified Indu...|Unclassified Indu...|Unclassified Indu...|Unclassified Indu...|[  \"SAP Logistics...|   [  \"SAP Logistics...|                 []|                []|[  \"SAP Logistics...|Business Intellig...|Information Techn...|Business Intellig...|            SAP Analyst / Admin|     Business Intellig...|               SAP Analyst / Admin|  Business Intellig...|        Business Intellig...|   Information Techn...|Computer and Math...|Mathematical Scie...|Data Scientists|Data Scientists|      Onsite|                TX|        Red|       108668.5|\n| [  \"No Education ...|No Education Listed|           Full-Time|                 0.0|  52000.0|    39000.0| 45500.0|          Miami, FL|Miami-Fort Lauder...|   Florida|Unclassified Indu...|Unclassified Indu...|Unclassified Indu...|Unclassified Indu...|Unclassified Indu...|                  []|                     []|                 []|                []|                  []|Business Intellig...|Business Manageme...|Business / Manage...|           Business Analyst ...|        Business Analysis|              Business Analyst ...|  Business / Manage...|           Business Analysis|   Business Manageme...|Computer and Math...|Mathematical Scie...|Data Scientists|Data Scientists|      Onsite|                FL|        Red|        45500.0|\n| [  \"No Education ...|No Education Listed|           Full-Time|                 0.0| 130042.0|    87295.0|115024.0|    Los Fresnos, TX|Brownsville-Harli...|     Texas|Unclassified Indu...|Unclassified Indu...|Unclassified Indu...|Unclassified Indu...|Unclassified Indu...|                  []|                     []|                 []|                []|                  []|Business Intellig...|Business Manageme...|Business / Manage...|           Business Analyst ...|        Business Analysis|              Business Analyst ...|  Business / Manage...|           Business Analysis|   Business Manageme...|Computer and Math...|Mathematical Scie...|Data Scientists|Data Scientists|      Onsite|                TX|        Red|       108668.5|\n| [  \"No Education ...|No Education Listed|           Full-Time|                 0.0| 130042.0|    87295.0|115024.0|Fort Lauderdale, FL|Miami-Fort Lauder...|   Florida|Unclassified Indu...|Unclassified Indu...|Unclassified Indu...|Unclassified Indu...|Unclassified Indu...|   [  \"Landscaping\"]|      [  \"Landscaping\"]|                 []|                []|                  []|Business Intellig...|Business Manageme...|Business / Manage...|           Business Analyst ...|        Business Analysis|              Business Analyst ...|  Business / Manage...|           Business Analysis|   Business Manageme...|Computer and Math...|Mathematical Scie...|Data Scientists|Data Scientists|      Onsite|                FL|        Red|       108668.5|\n+---------------------+-------------------+--------------------+--------------------+---------+-----------+--------+-------------------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+-------------------+------------------+--------------------+--------------------+--------------------+--------------------+-------------------------------+-------------------------+----------------------------------+----------------------+----------------------------+-----------------------+--------------------+--------------------+---------------+---------------+------------+------------------+-----------+---------------+\nonly showing top 15 rows\n\n```\n:::\n:::\n\n\n## Introduction\n\nThe following visualizations are based on the lightcast job postings data frame that was cleaned in the previous section. This analysis explores different facets of the data specifically related to the political affiliation of the states and the different job postings in each state. We also take a closer look at AI related jobs and the impact of political climate on salary. \n\n\n## Exploring the Salary by State Political Affiliation\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nfrom pyspark.sql import functions as F\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\neda = eda.na.drop(subset=[\"AFFILIATION\"])\n\n# Aggregate the Data \nsalary_by_affiliation = (\n    eda.groupBy(\"AFFILIATION\",\"NAICS2_NAME\")\n      .agg(\n          F.mean(\"SALARY\").alias(\"avg_salary\"),\n          F.expr(\"percentile_approx(SALARY, 0.5)\").alias(\"median_salary\"),\n          F.count(\"*\").alias(\"count\")\n      )\n      .orderBy(\"avg_salary\", ascending=False)\n)\n\n#salary_by_affiliation.show()\n\npdf = salary_by_affiliation.toPandas()\n\n# visualize the data\nfig = px.bar(\n    pdf,\n    x=\"NAICS2_NAME\",\n    y=\"avg_salary\",\n    color=\"AFFILIATION\",\n    barmode=\"group\",\n    hover_data=[\"median_salary\", \"count\"], \n    labels={\n        \"NAICS2_NAME\": \"Industry (NAICS2)\",\n        \"avg_salary\": \"Average Salary\",\n        \"AFFILIATION\": \"Political Affiliation\"\n    },\n    title=\"Average Salary by Industry and Political Affiliation\"\n)\n\nfig.update_layout(\n    xaxis_tickangle=-45,\n    yaxis_title=\"Average Salary\",\n    xaxis_title=\"Industry (NAICS2)\",\n    legend_title=\"Affiliation\",\n    template=\"plotly_white\"\n)\n\nfig.show()\n\nfig.write_html(\"./output/salary_affiliation.html\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\r[Stage 41:>                                                         (0 + 1) / 1]\r\r                                                                                \r\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```\nUnable to display output for mime type(s): text/html\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```\nUnable to display output for mime type(s): text/html\n```\n:::\n:::\n\n\n```{=html}\n<iframe width=\"900\" height=\"650\" src=\"./output/salary_affiliation.html\" title=\"Salary By State Political Affiliation\"></iframe>\n```\n\nThis data clearly shows that average salaries are slightly higher in Blue states vs Red States across nearly all NAICS2 categories. In red states, Professional, Scientific, and Technical Services has a slightly higher average salary. \n\n## Exploring the minimum education level by political affiliation\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nimport plotly.express as px\n\n# Aggregate the Data \nedulevel_by_affiliation = (\n    eda.groupBy(\"AFFILIATION\",\"MIN_EDULEVELS_NAME\")\n      .agg(\n           F.count(\"*\").alias(\"count\"),\n          F.mean(\"SALARY\").alias(\"avg_salary\")\n      )\n)\n\nedulevel_by_affiliation.show()\n\npdf = edulevel_by_affiliation.toPandas()\n\n# visualize the data\nfig = px.bar(\n    pdf,\n    x=\"MIN_EDULEVELS_NAME\",\n    y=\"count\",\n    color=\"AFFILIATION\",\n    barmode=\"group\",\n    title=\"Education Level Requirements by Political Affiliation\",\n    hover_data=[\"avg_salary\"],  # optional: show avg salary on hover\n    color_discrete_map={\"Blue\": \"#1f77b4\", \"Red\": \"#d62728\"}\n)\n\nfig.update_layout(\n    xaxis_title=\"Minimum Education Level\",\n    yaxis_title=\"Number of Postings\",\n    template=\"plotly_white\"\n)\n\nfig.show()\n\nfig.write_html(\"./output/education_affiliation.html\")\n\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\r[Stage 49:>                                                         (0 + 1) / 1]\r\r                                                                                \r\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n+-----------+--------------------+-----+------------------+\n|AFFILIATION|  MIN_EDULEVELS_NAME|count|        avg_salary|\n+-----------+--------------------+-----+------------------+\n|       Blue|Ph.D. or professi...|   65|121177.26153846153|\n|       Blue|     Master's degree|  975|127811.44102564102|\n|        Red|Ph.D. or professi...|   45|101607.06666666667|\n|       Blue| No Education Listed|10313|117231.11810336469|\n|       Blue|    Associate degree| 1058|116931.42722117202|\n|        Red|  High school or GED| 1992|  97134.2093373494|\n|       Blue|  High school or GED| 1563| 99052.77095329495|\n|       Blue|   Bachelor's degree|18247|118800.53685537349|\n|        Red|   Bachelor's degree|21201|116179.15782274421|\n|        Red| No Education Listed|11088|114194.55952380953|\n|        Red|     Master's degree|  720|126568.86388888888|\n|        Red|    Associate degree| 1914|116796.46603970742|\n+-----------+--------------------+-----+------------------+\n\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\r[Stage 52:>                                                         (0 + 1) / 1]\r\r                                                                                \r\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```\nUnable to display output for mime type(s): text/html\n```\n:::\n:::\n\n\n```{=html}\n<iframe width=\"900\" height=\"650\" src=\"./output/education_affiliation.html\" title=\"Min Education Levels by State Political Affiliation\"></iframe>\n```\n\n\nThis graph shows us the comparison of job postings by political affiliation and minimum education level. As you can see, red states have far more job postings for lower education levels such as High School, Associate Degree, or Bachelor's degree, and blue states have more postings requiring a Master's Degree or higher. \n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nfig = px.bar(\n    pdf,\n    x=\"MIN_EDULEVELS_NAME\",\n    y=\"avg_salary\",\n    color=\"AFFILIATION\",\n    barmode=\"group\",\n    title=\"Average Salary by Education Level and Political Affiliation\",\n    hover_data=[\"count\"],\n    color_discrete_map={\"Blue\": \"#1f77b4\", \"Red\": \"#d62728\"}\n)\n\nfig.update_layout(\n    xaxis_title=\"Minimum Education Level\",\n    yaxis_title=\"Average Salary (USD)\",\n    template=\"plotly_white\"\n)\n\nfig.show()\n\nfig.write_html(\"./output/salary_education_affiliation.html\")\n\n```\n\n::: {.cell-output .cell-output-display}\n```\nUnable to display output for mime type(s): text/html\n```\n:::\n:::\n\n\n```{=html}\n<iframe width=\"900\" height=\"650\" src=\"./output/salary_education_affiliation.html\" title=\"Average Salary by Min Education Levels and State Political Affiliation\"></iframe>\n```\n\n\nThis figure tells us that despite red states having more job postings with education level requirements below a Master's degree, the salaries in Blue states are higher for every single minimum education level. This could be attributed to a higher cost of living in most blue states. \n\n## AI Jobs Analysis\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\nfrom pyspark.sql import functions as F\n\nai_keywords = [\n    \"artificial intelligence\", \"machine learning\", \"deep learning\",\n    \"neural network\", \"nlp\", \"natural language processing\",\n    \"computer vision\", \"data science\", \"data scientist\",\n    \"ai engineer\", \"ai research\", \"ml engineer\",\n    \"tensorflow\", \"pytorch\", \"keras\", \"hugging face\", \"openai\", \"scikit-learn\"\n]\npattern = \"|\".join([f\"(?i){kw}\" for kw in ai_keywords])\n\nai_jobs = eda.filter(\n    F.col(\"SKILLS_NAME\").rlike(pattern) |\n    F.col(\"SPECIALIZED_SKILLS_NAME\").rlike(pattern) |\n    F.col(\"SOFTWARE_SKILLS_NAME\").rlike(pattern) |\n    F.col(\"COMMON_SKILLS_NAME\").rlike(pattern) |\n    F.col(\"LOT_OCCUPATION_NAME\").rlike(pattern) |\n    F.col(\"ONET_NAME\").rlike(pattern)\n)\n\nai_jobs.select(\"MIN_EDULEVELS_NAME\",\"LOT_OCCUPATION_NAME\", \"SKILLS_NAME\", \"SALARY\", \"STATE_ABBREVIATION\",\"AFFILIATION\",\"NAICS2_NAME\",\"NAICS3_NAME\",\"NAICS4_NAME\",\"NAICS5_NAME\",\"NAICS6_NAME\").show(10, truncate=False)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n+-------------------+-------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+------------------+-----------+------------------------------------------------+----------------------------------------------------------------------------+--------------------------------------------------------------+--------------------------------------------------------------+---------------------------------------+\n|MIN_EDULEVELS_NAME |LOT_OCCUPATION_NAME                  |SKILLS_NAME                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |SALARY  |STATE_ABBREVIATION|AFFILIATION|NAICS2_NAME                                     |NAICS3_NAME                                                                 |NAICS4_NAME                                                   |NAICS5_NAME                                                   |NAICS6_NAME                            |\n+-------------------+-------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+------------------+-----------+------------------------------------------------+----------------------------------------------------------------------------+--------------------------------------------------------------+--------------------------------------------------------------+---------------------------------------+\n|No Education Listed|Business Intelligence Analyst        |[  \"Artificial Intelligence\",  \"Angular (Web Framework)\",  \"ClickUp (Software)\",  \"Cyber Defense\",  \"Cyber Security\",  \"Engineering Management\",  \"Front End Design\",  \"Manufacturing Execution System (MES)\",  \"Operations\",  \"Project Management\",  \"SAP Applications\",  \"Wax\"]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |115024.0|TX                |Red        |Unclassified Industry                           |Unclassified Industry                                                       |Unclassified Industry                                         |Unclassified Industry                                         |Unclassified Industry                  |\n|Bachelor's degree  |Data / Data Mining Analyst           |[  \"Chemical Engineering\",  \"Mechanical Engineering\",  \"Power BI\",  \"Forecasting\",  \"Hydraulics\",  \"Data Science\",  \"Data Engineering\",  \"Spreadsheets\",  \"Cost Benefit Analysis\",  \"Communication\",  \"Python (Programming Language)\",  \"Oil and Gas\",  \"Data Analysis\",  \"Statistical Modeling\",  \"SQL (Programming Language)\",  \"Data Modeling\",  \"Mathematics\",  \"Data Visualization\",  \"Computer Science\"]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |140400.0|TX                |Red        |Unclassified Industry                           |Unclassified Industry                                                       |Unclassified Industry                                         |Unclassified Industry                                         |Unclassified Industry                  |\n|No Education Listed|Business / Management Analyst        |[  \"Business Communication\",  \"Data Science\",  \"Business Concepts\",  \"Project Management\",  \"Business Process\",  \"Communication\",  \"Time Management\",  \"Product Management\",  \"Data Analysis\",  \"Marketing\",  \"Stakeholder Management\",  \"Market Research\",  \"Business Intelligence\",  \"Business Operations\",  \"Cyber Security\",  \"Organizational Skills\",  \"Willingness To Learn\",  \"User Experience (UX)\",  \"Sales\",  \"Software Development\",  \"Problem Solving\",  \"Teaching\",  \"Compensation Analysis\"]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |115024.0|IN                |Red        |Unclassified Industry                           |Unclassified Industry                                                       |Unclassified Industry                                         |Unclassified Industry                                         |Unclassified Industry                  |\n|No Education Listed|Data / Data Mining Analyst           |[  \"Salesforce\",  \"Apache Hadoop\",  \"C++ (Programming Language)\",  \"Gamification\",  \"Business Objectives\",  \"Data Mining\",  \"Data Processing\",  \"Collibra (Software)\",  \"Project Management\",  \"Finance\",  \"Algorithms\",  \"Python (Programming Language)\",  \"Apache Spark\",  \"Dashboard\",  \"Decision Making\",  \"Wealth Management\",  \"Machine Learning\",  \"Predictive Modeling\",  \"Natural Language Processing (NLP)\",  \"Microsoft Excel\",  \"SAS (Software)\",  \"Data Governance\",  \"Artificial Intelligence\",  \"Innovation\",  \"Data Visualization\",  \"Tableau (Business Intelligence Software)\",  \"R (Programming Language)\",  \"SQL (Programming Language)\"]                                                                                                                                                                                                                                                                                                                                                     |115024.0|NY                |Blue       |Unclassified Industry                           |Unclassified Industry                                                       |Unclassified Industry                                         |Unclassified Industry                                         |Unclassified Industry                  |\n|Bachelor's degree  |Data / Data Mining Analyst           |[  \"Power BI\",  \"Programming Languages\",  \"Customer Experience Improvement\",  \"Self-Motivation\",  \"Data Science\",  \"Linux\",  \"Python (Programming Language)\",  \"Sustaining Engineering\",  \"Data Analysis\",  \"Program Process Monitoring\",  \"Java (Programming Language)\",  \"SQL (Programming Language)\",  \"Product Engineering\",  \"Data Collection\",  \"Design Studio\",  \"Amazon Web Services\",  \"Software Development\",  \"Product Quality (QA/QC)\",  \"Data Visualization\",  \"Tableau (Business Intelligence Software)\",  \"Computer Science\"]                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |71458.0 |WI                |Red        |Unclassified Industry                           |Unclassified Industry                                                       |Unclassified Industry                                         |Unclassified Industry                                         |Unclassified Industry                  |\n|Bachelor's degree  |Computer Systems Engineer / Architect|[  \"Inventory Staging\",  \"Relational Databases\",  \"Computer Engineering\",  \"Star Schema\",  \"Information Technology\",  \"Management\",  \"Management Information Systems\",  \"Agile Methodology\",  \"Process Improvement\",  \"Application Development\",  \"Erwin (Data Modeling Software)\",  \"Data Science\",  \"Data Warehousing\",  \"Metadata Management\",  \"Amazon Redshift\",  \"Data Architecture\",  \"Interpersonal Communications\",  \"Cost Benefit Analysis\",  \"Waterfall Methodology\",  \"Aurora (Operating System)\",  \"Communication\",  \"Textiles\",  \"Systems Development Life Cycle\",  \"Leadership\",  \"Information Systems\",  \"Data Quality\",  \"Data Analysis\",  \"Business Requirements\",  \"Extract Transform Load (ETL)\",  \"SQL (Programming Language)\",  \"Operational Data Store\",  \"Data Modeling\",  \"Machine Learning\",  \"Third Normal Form\",  \"Change Management\",  \"Mentorship\",  \"Business Administration\",  \"Document-Oriented Databases\",  \"Data Strategy\",  \"Computer Science\"]                             |147650.0|SD                |Red        |Unclassified Industry                           |Unclassified Industry                                                       |Unclassified Industry                                         |Unclassified Industry                                         |Unclassified Industry                  |\n|No Education Listed|Business / Management Analyst        |[  \"Information Retrieval\",  \"Research\",  \"Data Infrastructure\",  \"Business Analytics\",  \"Innovation\",  \"Experimental Design\",  \"Statistical Analysis\",  \"Data Mining\",  \"Automation\",  \"Data Science\",  \"Data Engineering\",  \"Amazon Redshift\",  \"Data Architecture\",  \"Timelines\",  \"Requirements Management\",  \"Python (Programming Language)\",  \"Leadership\",  \"Supply Chain\",  \"Machine Learning\",  \"Communication\",  \"Business Intelligence\",  \"SQL (Programming Language)\",  \"Scalability\",  \"Scripting\",  \"Amazon Web Services\",  \"Data Integrity\",  \"Extract Transform Load (ETL)\"]                                                                                                                                                                                                                                                                                                                                                                                                                     |160050.0|WA                |Blue       |Retail Trade                                    |Sporting Goods, Hobby, Musical Instrument, Book, and Miscellaneous Retailers|Other Miscellaneous Retailers                                 |All Other Miscellaneous Retailers                             |All Other Miscellaneous Retailers      |\n|No Education Listed|Business Intelligence Analyst        |[  \"Information Retrieval\",  \"Inventory Planning\",  \"Analytical Skills\",  \"Experimental Design\",  \"Statistical Analysis\",  \"Data Mining\",  \"Self-Motivation\",  \"Automation\",  \"Data Science\",  \"Supply Chain Optimization\",  \"Business Metrics\",  \"Data Engineering\",  \"Supply Chain Acumen\",  \"Innovation\",  \"Python (Programming Language)\",  \"Leadership\",  \"Data Analysis\",  \"Machine Learning\",  \"Communication\",  \"Business Intelligence\",  \"Detail Oriented\",  \"SQL (Programming Language)\",  \"Scalability\",  \"Scripting\",  \"Amazon Web Services\",  \"Product Description\",  \"Data Visualization\"]                                                                                                                                                                                                                                                                                                                                                                                                         |160050.0|WA                |Blue       |Retail Trade                                    |Sporting Goods, Hobby, Musical Instrument, Book, and Miscellaneous Retailers|Other Miscellaneous Retailers                                 |All Other Miscellaneous Retailers                             |All Other Miscellaneous Retailers      |\n|Bachelor's degree  |Data / Data Mining Analyst           |[  \"Certified Information System Auditor (CISA)\",  \"Apache Hadoop\",  \"Prioritization\",  \"Coaching\",  \"Planning\",  \"Certified Fraud Examiner\",  \"Statistical Analysis\",  \"Self-Motivation\",  \"Data Science\",  \"Finance\",  \"Certified Analytics Professional\",  \"Communication\",  \"Innovation\",  \"Python (Programming Language)\",  \"Forensic Sciences\",  \"Emerging Technologies\",  \"Decision Making\",  \"Data Analysis\",  \"SQL (Programming Language)\",  \"SAS (Software)\",  \"Certified Information Systems Security Professional\",  \"Certified Information Security Manager\",  \"Scripting\",  \"Power BI\",  \"SPSS (Statistical Software)\",  \"Data Visualization\",  \"R (Programming Language)\"]                                                                                                                                                                                                                                                                                                                        |140300.0|NC                |Red        |Professional, Scientific, and Technical Services|Professional, Scientific, and Technical Services                            |Accounting, Tax Preparation, Bookkeeping, and Payroll Services|Accounting, Tax Preparation, Bookkeeping, and Payroll Services|Offices of Certified Public Accountants|\n|Bachelor's degree  |Data / Data Mining Analyst           |[  \"Workflow Management\",  \"General Data Protection Regulation (GDPR)\",  \"Analytic Applications\",  \"Medical Records\",  \"Electronic Medical Record\",  \"Agile Methodology\",  \"Value-Based Care\",  \"Health Administration\",  \"Project Status Reports\",  \"Data Science\",  \"Data Management\",  \"Healthcare Industry Knowledge\",  \"Big Data\",  \"Statistical Modeling\",  \"Informatics\",  \"Scrum (Software Development)\",  \"Communication\",  \"Valid Driver's License\",  \"Listening Skills\",  \"Decision Making\",  \"Data Analysis\",  \"Customer Data Management\",  \"Data Cleansing\",  \"Fast Healthcare Interoperability Resources (FHIR)\",  \"Business Requirements\",  \"Investigation\",  \"Project Management\",  \"Data Modeling\",  \"Key Performance Indicators (KPIs)\",  \"Scalability\",  \"Technology Solutions\",  \"Health Insurance Portability And Accountability Act (HIPAA) Compliance\",  \"ASC X12 Standards\",  \"Power BI\",  \"Problem Solving\",  \"SQL (Programming Language)\",  \"Tableau (Business Intelligence Software)\"]|164600.0|PA                |Red        |Professional, Scientific, and Technical Services|Professional, Scientific, and Technical Services                            |Accounting, Tax Preparation, Bookkeeping, and Payroll Services|Accounting, Tax Preparation, Bookkeeping, and Payroll Services|Offices of Certified Public Accountants|\n+-------------------+-------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+------------------+-----------+------------------------------------------------+----------------------------------------------------------------------------+--------------------------------------------------------------+--------------------------------------------------------------+---------------------------------------+\nonly showing top 10 rows\n\n```\n:::\n:::\n\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\nimport plotly.express as px\n\n# Aggregate the Data \nai_job_analysis = (\n    ai_jobs.groupBy(\"AFFILIATION\",\"MIN_EDULEVELS_NAME\")\n      .agg(\n           F.count(\"*\").alias(\"count\"),\n          F.mean(\"SALARY\").alias(\"avg_salary\")\n      )\n)\n\nai_job_analysis.show()\n\nai_pdf = ai_job_analysis.toPandas()\n\n# visualize the data\nfig = px.bar(\n    ai_pdf,\n    x=\"MIN_EDULEVELS_NAME\",\n    y=\"count\",\n    color=\"AFFILIATION\",\n    barmode=\"group\",\n    title=\"AI jobs Education Level Requirements by Political Affiliation\",\n    hover_data=[\"avg_salary\"],\n    color_discrete_map={\"Blue\": \"#1f77b4\", \"Red\": \"#d62728\"}\n)\n\nfig.update_layout(\n    xaxis_title=\"Minimum Education Level\",\n    yaxis_title=\"Number of Postings\",\n    template=\"plotly_white\"\n)\n\nfig.show()\n\nfig.write_html(\"./output/AI_education_affiliation.html\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\r[Stage 56:>                                                         (0 + 1) / 1]\r\r                                                                                \r\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n+-----------+--------------------+-----+------------------+\n|AFFILIATION|  MIN_EDULEVELS_NAME|count|        avg_salary|\n+-----------+--------------------+-----+------------------+\n|       Blue|Ph.D. or professi...|   13|114372.30769230769|\n|       Blue|     Master's degree|  367| 122253.1553133515|\n|        Red|Ph.D. or professi...|   11|105201.45454545454|\n|       Blue| No Education Listed|  942|125017.12101910828|\n|       Blue|    Associate degree|  203|          133256.0|\n|        Red|  High school or GED|  114|104949.07894736843|\n|       Blue|  High school or GED|  128|    111645.7265625|\n|       Blue|   Bachelor's degree| 3582|121041.59491903965|\n|        Red|   Bachelor's degree| 3632|116541.23595814977|\n|        Red| No Education Listed|  841|113824.22948870392|\n|        Red|     Master's degree|  221|119314.45248868778|\n|        Red|    Associate degree|  290|130392.43793103448|\n+-----------+--------------------+-----+------------------+\n\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\r[Stage 59:>                                                         (0 + 1) / 1]\r\r                                                                                \r\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```\nUnable to display output for mime type(s): text/html\n```\n:::\n:::\n\n\n```{=html}\n<iframe width=\"900\" height=\"650\" src=\"./output/AI_education_affiliation.html\" title=\"AI Jobs by Min Education Levels and State Political Affiliation\"></iframe>\n```\n\n\nThis figure shows us the number of postings just with certain key words related to AI. It groups by education level and political affiliation. The graph tells us that the distribution of number of  AI job postings across education level and affiliation mirrors that of the larger data set. Thus, AI jobs are not posted at any higher frequency across red or blue states than any other job.\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\nfig = px.bar(\n    ai_pdf,\n    x=\"MIN_EDULEVELS_NAME\",\n    y=\"avg_salary\",\n    color=\"AFFILIATION\",\n    barmode=\"group\",\n    title=\"AI Jobs Average Salary by Education Level and Political Affiliation\",\n    hover_data=[\"count\"], \n    color_discrete_map={\"Blue\": \"#1f77b4\", \"Red\": \"#d62728\"}\n)\n\nfig.update_layout(\n    xaxis_title=\"Minimum Education Level\",\n    yaxis_title=\"Average Salary (USD)\",\n    template=\"plotly_white\"\n)\n\nfig.show()\n\nfig.write_html(\"./output/AI_salary_education_affiliation.html\")\n```\n\n::: {.cell-output .cell-output-display}\n```\nUnable to display output for mime type(s): text/html\n```\n:::\n:::\n\n\n```{=html}\n<iframe width=\"900\" height=\"650\" src=\"./output/AI_salary_education_affiliation.html\" title=\"AI Job Salaries by Min Education Levels and State Political Affiliation\"></iframe>\n```\n\nSimilarly, in this figure, AI Jobs show salary distributions equivalent to that of jobs in other industries. Like the general analysis, blue states offer higher salaries for AI jobs across each of education levels. Again, this is likely due to the higher cost of living in most blue states. \n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\nstate_counts = (\n    ai_jobs.groupBy(\"STATE_ABBREVIATION\", \"AFFILIATION\")\n       .agg(\n           F.count(\"*\").alias(\"count\"),\n           F.mean(\"SALARY\").alias(\"avg_salary\")\n       )\n       .orderBy(F.desc(\"count\"))\n)\nstate_counts.show(10, truncate=False)\n\nstate_counts_pd = state_counts.toPandas()\n\nimport plotly.express as px\n\nstate_counts_pd_sorted = state_counts_pd.sort_values(\"count\", ascending=True)\n\nfig = px.bar(\n    state_counts_pd_sorted,\n    x=\"count\",\n    y=\"STATE_ABBREVIATION\",\n    orientation=\"h\",\n    color = \"AFFILIATION\",\n    color_discrete_map={\n    \"Red\": \"red\",\n    \"Blue\": \"blue\"\n    },\n    hover_data=[\"avg_salary\"],  # Show average salary on hover\n    title=\"Number of AI Job Postings by State and Affiliation\",\n    labels={\"count\": \"Job Postings\", \"STATE_ABBREVIATION\": \"State\"}\n)\n\nfig.update_layout(\n    yaxis={'categoryorder':'total ascending'},\n    xaxis_title=\"Number of Job Postings\",\n    yaxis_title=\"State\",\n    legend_title=\"Affiliation\",\n    template=\"plotly_white\"\n)\n\nfig.show()\n\nfig.write_html(\"./output/AI_byState.html\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\r[Stage 62:>                                                         (0 + 1) / 1]\r\r                                                                                \r\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n+------------------+-----------+-----+------------------+\n|STATE_ABBREVIATION|AFFILIATION|count|avg_salary        |\n+------------------+-----------+-----+------------------+\n|CA                |Blue       |1058 |130800.25141776938|\n|TX                |Red        |1045 |119186.34354066986|\n|NY                |Blue       |617  |118399.72609400324|\n|VA                |Blue       |598  |116501.39632107023|\n|IL                |Blue       |480  |120063.675        |\n|FL                |Red        |447  |115597.10514541387|\n|GA                |Red        |419  |111773.3723150358 |\n|NC                |Red        |372  |117288.66935483871|\n|OH                |Red        |362  |114862.99171270718|\n|PA                |Red        |338  |118117.09467455621|\n+------------------+-----------+-----+------------------+\nonly showing top 10 rows\n\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\r[Stage 65:>                                                         (0 + 1) / 1]\r\r                                                                                \r\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```\nUnable to display output for mime type(s): text/html\n```\n:::\n:::\n\n\n```{=html}\n<iframe width=\"900\" height=\"900\" src=\"./output/AI_byState.html\" title=\"Number of AI Job Postings by State\"></iframe>\n```\n\nThis graph clearly shows that of the top 5 states with the most number of AI job postings, 4/5 of them are blue states. \n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\nimport plotly.express as px\nfrom pyspark.sql import functions as F\n\nai_naics = (ai_jobs.filter(col(\"NAICS2_NAME\") ==\"Professional, Scientific, and Technical Services\")\n)\n\nnaics_levels = [\"NAICS4_NAME\", \"NAICS5_NAME\", \"NAICS6_NAME\"]\n\nai_naicscounts_dfs = []\nfor level in naics_levels:\n    df = (\n        ai_naics.groupBy(level)\n           .agg(F.count(\"*\").alias(\"count\"))\n           .withColumnRenamed(level, \"Industry\")\n           .withColumn(\"NAICS_Level\", F.lit(level))\n    )\n    ai_naicscounts_dfs.append(df)\n\ncombined_ai_naicscounts = ai_naicscounts_dfs[0]\nfor df in ai_naicscounts_dfs[1:]:\n    combined_ai_naicscounts = combined_ai_naicscounts.union(df)\n\ncombined_ai_naicscounts = combined_ai_naicscounts.orderBy(F.desc(\"count\"))\n\n\nai_naics_combined = combined_ai_naicscounts.toPandas()\n\nai_naics_combined\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\r[Stage 73:>                                                         (0 + 1) / 1]\r\r[Stage 73:>                 (0 + 1) / 1][Stage 74:>                 (0 + 1) / 1]\r\r[Stage 73:>   (0 + 1) / 1][Stage 74:>   (0 + 1) / 1][Stage 75:>   (0 + 0) / 1]\r\r[Stage 74:>                 (0 + 1) / 1][Stage 75:>                 (0 + 1) / 1]\r\r[Stage 75:>                                                         (0 + 1) / 1]\r\r                                                                                \r\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=16}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Industry</th>\n      <th>count</th>\n      <th>NAICS_Level</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Computer Systems Design and Related Services</td>\n      <td>1554</td>\n      <td>NAICS4_NAME</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Computer Systems Design and Related Services</td>\n      <td>1554</td>\n      <td>NAICS5_NAME</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Management, Scientific, and Technical Consulti...</td>\n      <td>827</td>\n      <td>NAICS4_NAME</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Computer Systems Design Services</td>\n      <td>689</td>\n      <td>NAICS6_NAME</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Custom Computer Programming Services</td>\n      <td>647</td>\n      <td>NAICS6_NAME</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>Architectural Services</td>\n      <td>2</td>\n      <td>NAICS6_NAME</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>Public Relations Agencies</td>\n      <td>2</td>\n      <td>NAICS6_NAME</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>Translation and Interpretation Services</td>\n      <td>2</td>\n      <td>NAICS6_NAME</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>Direct Mail Advertising</td>\n      <td>1</td>\n      <td>NAICS5_NAME</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <td>Direct Mail Advertising</td>\n      <td>1</td>\n      <td>NAICS6_NAME</td>\n    </tr>\n  </tbody>\n</table>\n<p>64 rows × 3 columns</p>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\nfig = px.bar(\n    ai_naics_combined,\n    x=\"Industry\",\n    y=\"count\",\n    color = \"NAICS_Level\",\n    barmode=\"group\",\n    hover_data=[\"NAICS_Level\", \"count\"],\n    title=\"Job Posting Counts Across NAICS Levels 2–6\",\n    labels={\"count\": \"Job Postings\", \"Industry\": \"Industry\", \"NAICS_Level\": \"NAICS Level\"}\n)\n\n# Rotate x-axis labels for readability\nfig.update_layout(\n    xaxis_tickangle=-45,\n    yaxis_title=\"Number of Job Postings\",\n    xaxis_title=\"Industry\",\n    template=\"plotly_white\"\n)\n\nfig.show()\n\nfig.write_html(\"./output/AI_industries.html\")\n```\n\n::: {.cell-output .cell-output-display}\n```\nUnable to display output for mime type(s): text/html\n```\n:::\n:::\n\n\n```{=html}\n<iframe width=\"900\" height=\"900\" src=\"./output/AI_industries.html\" title=\"Number of AI Job Postings by Industry\"></iframe>\n```\n\nThis graph is showing us the number of job postings by NAICS. For AI jobs, the NAICS with the largest number of AI job postings. Computer Systems Design is predominate NAICS with consulting services coming in second. \n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\n#eda.select(\"NAICS2_NAME\").distinct().show(25, truncate = False)\n\nfrom pyspark.sql import functions as F\n\ngender_jobs = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"multiLine\",\"true\").option(\"escape\", \"\\\"\").csv(\"./data/Gender_Industries.csv\")\ngender_jobs.createOrReplaceTempView(\"gender_industries\")\n\n\nsorted_gender_jobs = (\n    gender_jobs\n    .orderBy(F.desc(\"TOTAL_NUMBER_OF_WOMEN\"))\n    .select(\"NAICS_NAME\", \"NUMBER_OF_PEOPLE\",\"TOTAL_NUMBER_OF_WOMEN\", \"PERCENT_WOMEN\")\n    .limit(10)\n)\n\n#sorted_gender_jobs.show()\n\nsorted_gender_jobs = sorted_gender_jobs.toPandas()\n```\n:::\n\n\n::: {.cell execution_count=19}\n``` {.python .cell-code}\nimport plotly.graph_objects as go\n\nfig = go.Figure()\n\nfig.add_trace(go.Bar(\n    x=sorted_gender_jobs[\"NAICS_NAME\"],\n    y=sorted_gender_jobs[\"TOTAL_NUMBER_OF_WOMEN\"],\n    name=\"Number of Women\",\n    yaxis=\"y1\"\n))\n\nfig.add_trace(go.Scatter(\n    x=sorted_gender_jobs[\"NAICS_NAME\"],\n    y=sorted_gender_jobs[\"PERCENT_WOMEN\"],\n    name=\"% Women\",\n    yaxis=\"y2\",\n    mode=\"lines+markers\"\n))\n\n\nfig.update_layout(\n    title=\"Top 10 Industries by Number of Women\",\n    xaxis=dict(title=\"Industry (NAICS_NAME)\"),\n    yaxis=dict(title=\"Number of Women\", side=\"left\"),\n    yaxis2=dict(\n        title=\"% Women\",\n        overlaying=\"y\",\n        side=\"right\"\n    ),\n    legend=dict(x=0.02, y=0.98),\n    template=\"plotly_white\",\n    xaxis_tickangle=-45\n)\n\nfig.show()\n\nfig.write_html(\"./output/gender_and_industry.html\")\n```\n\n::: {.cell-output .cell-output-display}\n```\nUnable to display output for mime type(s): text/html\n```\n:::\n:::\n\n\n```{=html}\n<iframe width=\"900\" height=\"900\" src=\"./output/gender_and_industry.html\" title=\"Industries With The Most Women vs Percent of Women in the Industry\"></iframe>\n```\n\nThe above graph has two different important features. First, it shows the top 10 industries for women on the bar chart, sorted by the overall number of women according the U.S. Bureau of Labor Statistics @bls2025cps. The second important feature is the line chart which shows the percentage of women in that field. As you can see, some of the most female dominated industries do not have very many women in them and some of the industries with the most women are heavily male dominated. \n\n::: {.cell execution_count=20}\n``` {.python .cell-code}\nfrom pyspark.sql import functions as F\nimport plotly.graph_objects as go\nfrom pyspark.sql.functions import col\n\ngender_jobs = gender_jobs.withColumn(\"NUMBER_OF_PEOPLE\", col (\"NUMBER_OF_PEOPLE\").cast(\"float\"))\n\nsorted_gender_jobs = (\n    gender_jobs\n    .orderBy(F.desc(\"NUMBER_OF_PEOPLE\"))\n    .select(\"NAICS_NAME\", \"NUMBER_OF_PEOPLE\",\"TOTAL_NUMBER_OF_WOMEN\", \"PERCENT_WOMEN\")\n    .limit(10)\n)\n\nsorted_gender_jobs.show()\nsorted_gender_jobs_pd = sorted_gender_jobs.toPandas()\n\n\nfig = go.Figure()\n\nfig.add_trace(go.Bar(\n    x=sorted_gender_jobs_pd[\"NAICS_NAME\"],\n    y=sorted_gender_jobs_pd[\"NUMBER_OF_PEOPLE\"],\n    name=\"Number of People\",\n    yaxis=\"y1\"\n))\n\nfig.add_trace(go.Scatter(\n    x=sorted_gender_jobs_pd[\"NAICS_NAME\"],\n    y=sorted_gender_jobs_pd[\"PERCENT_WOMEN\"],\n    name=\"% Women\",\n    yaxis=\"y2\",\n    mode=\"lines+markers\"\n))\n\nfig.update_layout(\n    title=\"Top 10 Industries by Number of People\",\n    xaxis=dict(title=\"Industry (NAICS_NAME)\"),\n    yaxis=dict(title=\"Percent Female\", side=\"left\"),\n    yaxis2=dict(\n        title=\"% Women\",\n        overlaying=\"y\",\n        side=\"right\"\n    ),\n    legend=dict(x=0.02, y=0.98),\n    template=\"plotly_white\",\n    xaxis_tickangle=-45\n)\n\nfig.show()\n\nfig.write_html(\"./output/industry_gender_gap.html\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n+--------------------+----------------+---------------------+-------------+\n|          NAICS_NAME|NUMBER_OF_PEOPLE|TOTAL_NUMBER_OF_WOMEN|PERCENT_WOMEN|\n+--------------------+----------------+---------------------+-------------+\n|Management, profe...|        7.0744E7|             36999112|         52.3|\n|Professional and ...|        4.0142E7|             23041508|         57.4|\n|Management, busin...|        3.0602E7|             13985114|         45.7|\n|Sales and office ...|        2.9885E7|             18050540|         60.4|\n| Service occupations|        2.6452E7|             15209900|         57.5|\n|Management occupa...|        2.0657E7|              8634626|         41.8|\n|Production, trans...|        1.9873E7|              4868885|         24.5|\n|Office and admini...|        1.5795E7|             11309220|         71.6|\n|Natural resources...|        1.4391E7|               863460|          6.0|\n|Sales and related...|         1.409E7|              6749110|         47.9|\n+--------------------+----------------+---------------------+-------------+\n\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```\nUnable to display output for mime type(s): text/html\n```\n:::\n:::\n\n\n```{=html}\n<iframe width=\"900\" height=\"900\" src=\"./output/industry_gender_gap.html\" title=\"Industries with the Most Number of People vs the Number of Women in Those Industries\"></iframe>\n```\n\nThe above figure shows the top 10 industries with the most number of employed individuals based on data from the U.S. Bureau of Labor Statistics @bls2025cps. The blue bars show the number of people in those industries, and the red bars show the number of women in the industry. \n\n::: {.cell execution_count=21}\n``` {.python .cell-code}\nfrom pyspark.sql import functions as F\nimport plotly.graph_objects as go\nfrom pyspark.sql.functions import col\nimport plotly.express as px\n\n\ngender_jobs_pd = gender_jobs.toPandas()\n\nai_gender = gender_jobs_pd[(gender_jobs_pd[\"NAICS_NAME\"] == \"Computer and mathematical occupations\") | (gender_jobs_pd[\"NAICS_NAME\"] == \"Computer systems analysts\")| (gender_jobs_pd[\"NAICS_NAME\"] == \"Information security analysts\") | (gender_jobs_pd[\"NAICS_NAME\"] == \"Computer programmers\") | (gender_jobs_pd[\"NAICS_NAME\"] == \"Software developers\") | (gender_jobs_pd[\"NAICS_NAME\"] == \"Database administrators and architects\") | (gender_jobs_pd[\"NAICS_NAME\"] == \"Network and computer systems administrators\") | (gender_jobs_pd[\"NAICS_NAME\"] == \"Computer network architects\") | (gender_jobs_pd[\"NAICS_NAME\"] == \"Computer occupations, all other\")]\n\nai_gender = ai_gender.sort_values(by = \"PERCENT_WOMEN\", ascending = False)\n\nfig = go.Figure()\n\nfig.add_trace(go.Bar(\n    x=ai_gender[\"NAICS_NAME\"],\n    y=ai_gender[\"NUMBER_OF_PEOPLE\"],\n    name=\"Number of People\",\n    yaxis=\"y1\"\n))\n\nfig.add_trace(go.Scatter(\n    x=ai_gender[\"NAICS_NAME\"],\n    y=ai_gender[\"PERCENT_WOMEN\"],\n    name=\"% Women\",\n    yaxis=\"y2\",\n    mode=\"lines+markers\"\n))\n\nfig.update_layout(\n    title=\"AI Industries and Female Representation\",\n    xaxis=dict(title=\"Industry (NAICS_NAME)\"),\n    yaxis=dict(title=\"Percent Female\", side=\"left\"),\n    yaxis2=dict(\n        title=\"% Women\",\n        overlaying=\"y\",\n        side=\"right\"\n    ),\n    legend=dict(x=0.02, y=0.98),\n    template=\"plotly_white\",\n    xaxis_tickangle=-45\n)\n\nfig.show()\n\nfig.write_html(\"./output/ai_gender.html\")\n```\n\n::: {.cell-output .cell-output-display}\n```\nUnable to display output for mime type(s): text/html\n```\n:::\n:::\n\n\n```{=html}\n<iframe width=\"900\" height=\"1500\" src=\"./output/ai_gender.html\" title=\"AI Industries and Female Representation\"></iframe>\n```\n\nThe above figure shows the representation of women in AI industries. It's worth noting that not a single one is female dominated, the highest female representation coming from Computer Systems Analysis with 43% female. The majority of these industries are less than 30% female. This displays a clear underrepresentation of females in AI industries. \n\n---\ntitle: \"Skills Gap Analysis\"\nformat:\n  html:\n    toc: false\n\nexecute:\n  echo: false\n  eval: true\n  output: true\n  freeze: auto\n---\n\n::: {.cell execution_count=22}\n``` {.python .cell-code}\nimport pandas as pd\nimport plotly.express as px\nimport plotly.io as pio\nfrom pyspark.sql import SparkSession\nimport re\nimport numpy as np\nimport plotly.graph_objects as go\nfrom pyspark.sql.functions import col, split, explode, regexp_replace, transform, when\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.functions import col, monotonically_increasing_id\n\nnp.random.seed(42)\n\npio.renderers.default = \"notebook\"\n\nspark = SparkSession.builder.appName(\"LightcastData\").getOrCreate()\n\njobs_df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"multiLine\",\"true\").option(\"escape\", \"\\\"\").csv(\"./data/lightcast_job_postings.csv\")\njobs_df.createOrReplaceTempView(\"job_postings\")\n\n#print(\"---This is Diagnostic check, No need to print it in the final doc---\")\n\n#df.printSchema() # comment this line when rendering the submission\n#jobs_df.show(5)\n#elections_df.show(5)\n\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n25/10/16 02:03:09 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n\r[Stage 96:>                                                         (0 + 1) / 1]\r\r                                                                                \r\n```\n:::\n:::\n\n\n::: {.cell execution_count=23}\n``` {.python .cell-code}\nimport pandas as pd\n\nskills_data = {\n    \"Name\": [\"Emily\",\"Pranathi\"],\n    \"Python\": [2,1],\n    \"Java\" :[2,1],\n    \"SQL\": [2,1],\n    \"Power BI\": [4,4],\n    \"Machine Learning\": [1,1],\n    \"Cloud Computing\": [2,2]\n}\n\ndf_skills = pd.DataFrame(skills_data)\ndf_skills.set_index(\"Name\", inplace=True)\ndf_skills\n```\n\n::: {.cell-output .cell-output-display execution_count=23}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Python</th>\n      <th>Java</th>\n      <th>SQL</th>\n      <th>Power BI</th>\n      <th>Machine Learning</th>\n      <th>Cloud Computing</th>\n    </tr>\n    <tr>\n      <th>Name</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Emily</th>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>4</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>Pranathi</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=24}\n``` {.python .cell-code}\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(8, 6))\nsns.heatmap(df_skills, annot=True, cmap=\"RdYlGn\", linewidths=0.5)\nplt.title(\"Team Skill Levels Heatmap\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](final_report_files/figure-docx/cell-25-output-1.png){}\n:::\n:::\n\n\n::: {.cell execution_count=25}\n``` {.python .cell-code}\n# view_cols = [\n#   \"BODY\",\n#   \"SKILLS_NAME\",\n#   \"SPECIALIZED_SKILLS_NAME\",\n#   \"CERTIFICATIONS_NAME\",\n#   \"COMMON_SKILLS_NAME\",\n#   \"SOFTWARE_SKILLS_NAME\"\n# ]\n\n# for colname in view_cols:\n#   print(f\"\\n----{colname} ----\")\n#   jobs_df.select(colname).distinct().show(60,truncate = False)\n```\n:::\n\n\n::: {.cell execution_count=26}\n``` {.python .cell-code}\nfrom collections import Counter\n\nskills_pd = jobs_df.select(\"SKILLS_NAME\").toPandas()\n\ntop_skills = [\"Python\",\"Java\",\"Power BI\",\"Machine Learning\",\"Cloud Computing\"]\n\nskill_counts = Counter()\nfor skill in top_skills:\n    skill_counts[skill] = skills_pd['SKILLS_NAME'].str.contains(skill, case=False, regex=True).sum()\n\njob_skill_counts = Counter(top_skills)\n\nfor skill in top_skills:\n    if skill not in df_skills.columns:\n        df_skills[skill] = 0  \n\ndf_skills.loc[\"Job Postings Count\"] = [skill_counts.get(skill, 0) for skill in df_skills.columns]\n\ndf_skills\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\r[Stage 97:>                                                         (0 + 1) / 1]\r\r                                                                                \r\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=26}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Python</th>\n      <th>Java</th>\n      <th>SQL</th>\n      <th>Power BI</th>\n      <th>Machine Learning</th>\n      <th>Cloud Computing</th>\n    </tr>\n    <tr>\n      <th>Name</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Emily</th>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>4</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>Pranathi</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>Job Postings Count</th>\n      <td>12350</td>\n      <td>4470</td>\n      <td>0</td>\n      <td>10850</td>\n      <td>4324</td>\n      <td>2555</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nBased on our Skills Gap Analysis, we need to work on our Python skills. In order to be more competitive in the job market, we will finish the Python DataCamp and practice incorporating our new skills into our current roles. \n\n---\ntitle: \"ML Methods\"\nformat:\n  html:\n    code-fold: true\n    code-overflow: wrap\n    code-summary: \"Show code\"\n    code-tools: true\n\nexecute:\n  echo: true\n  eval: true\n  output: true\n  freeze: auto\n---\n\n::: {#setup-topic-2-2 .cell execution_count=27}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.io as pio\nfrom plotly.subplots import make_subplots\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import mean_squared_error, r2_score, silhouette_score\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set Plotly theme\npio.templates.default = \"plotly_white\"\n\nprint(\"✓ All libraries loaded successfully!\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n✓ All libraries loaded successfully!\n```\n:::\n:::\n\n\n## Data Loading and Exploration\n\n::: {.cell execution_count=28}\n``` {.python .cell-code}\n# Load lightcast job postings data\ndf = pd.read_csv('data/lightcast_job_postings.csv')\n\nprint(f\"Dataset Shape: {df.shape[0]:,} rows × {df.shape[1]} columns\")\nprint(f\"\\nFirst few rows:\")\ndf.head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDataset Shape: 72,498 rows × 131 columns\n\nFirst few rows:\n```\n:::\n\n::: {#load-data-topic-2-2 .cell-output .cell-output-display execution_count=28}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>LAST_UPDATED_DATE</th>\n      <th>LAST_UPDATED_TIMESTAMP</th>\n      <th>DUPLICATES</th>\n      <th>POSTED</th>\n      <th>EXPIRED</th>\n      <th>DURATION</th>\n      <th>SOURCE_TYPES</th>\n      <th>SOURCES</th>\n      <th>URL</th>\n      <th>...</th>\n      <th>NAICS_2022_2</th>\n      <th>NAICS_2022_2_NAME</th>\n      <th>NAICS_2022_3</th>\n      <th>NAICS_2022_3_NAME</th>\n      <th>NAICS_2022_4</th>\n      <th>NAICS_2022_4_NAME</th>\n      <th>NAICS_2022_5</th>\n      <th>NAICS_2022_5_NAME</th>\n      <th>NAICS_2022_6</th>\n      <th>NAICS_2022_6_NAME</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1f57d95acf4dc67ed2819eb12f049f6a5c11782c</td>\n      <td>9/6/2024</td>\n      <td>2024-09-06 20:32:57.352 Z</td>\n      <td>0.0</td>\n      <td>6/2/2024</td>\n      <td>6/8/2024</td>\n      <td>6.0</td>\n      <td>[\\n  \"Company\"\\n]</td>\n      <td>[\\n  \"brassring.com\"\\n]</td>\n      <td>[\\n  \"https://sjobs.brassring.com/TGnewUI/Sear...</td>\n      <td>...</td>\n      <td>44.0</td>\n      <td>Retail Trade</td>\n      <td>441.0</td>\n      <td>Motor Vehicle and Parts Dealers</td>\n      <td>4413.0</td>\n      <td>Automotive Parts, Accessories, and Tire Retailers</td>\n      <td>44133.0</td>\n      <td>Automotive Parts and Accessories Retailers</td>\n      <td>441330.0</td>\n      <td>Automotive Parts and Accessories Retailers</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0cb072af26757b6c4ea9464472a50a443af681ac</td>\n      <td>8/2/2024</td>\n      <td>2024-08-02 17:08:58.838 Z</td>\n      <td>0.0</td>\n      <td>6/2/2024</td>\n      <td>8/1/2024</td>\n      <td>NaN</td>\n      <td>[\\n  \"Job Board\"\\n]</td>\n      <td>[\\n  \"maine.gov\"\\n]</td>\n      <td>[\\n  \"https://joblink.maine.gov/jobs/1085740\"\\n]</td>\n      <td>...</td>\n      <td>56.0</td>\n      <td>Administrative and Support and Waste Managemen...</td>\n      <td>561.0</td>\n      <td>Administrative and Support Services</td>\n      <td>5613.0</td>\n      <td>Employment Services</td>\n      <td>56132.0</td>\n      <td>Temporary Help Services</td>\n      <td>561320.0</td>\n      <td>Temporary Help Services</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>85318b12b3331fa490d32ad014379df01855c557</td>\n      <td>9/6/2024</td>\n      <td>2024-09-06 20:32:57.352 Z</td>\n      <td>1.0</td>\n      <td>6/2/2024</td>\n      <td>7/7/2024</td>\n      <td>35.0</td>\n      <td>[\\n  \"Job Board\"\\n]</td>\n      <td>[\\n  \"dejobs.org\"\\n]</td>\n      <td>[\\n  \"https://dejobs.org/dallas-tx/data-analys...</td>\n      <td>...</td>\n      <td>52.0</td>\n      <td>Finance and Insurance</td>\n      <td>524.0</td>\n      <td>Insurance Carriers and Related Activities</td>\n      <td>5242.0</td>\n      <td>Agencies, Brokerages, and Other Insurance Rela...</td>\n      <td>52429.0</td>\n      <td>Other Insurance Related Activities</td>\n      <td>524291.0</td>\n      <td>Claims Adjusting</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1b5c3941e54a1889ef4f8ae55b401a550708a310</td>\n      <td>9/6/2024</td>\n      <td>2024-09-06 20:32:57.352 Z</td>\n      <td>1.0</td>\n      <td>6/2/2024</td>\n      <td>7/20/2024</td>\n      <td>48.0</td>\n      <td>[\\n  \"Job Board\"\\n]</td>\n      <td>[\\n  \"disabledperson.com\",\\n  \"dejobs.org\"\\n]</td>\n      <td>[\\n  \"https://www.disabledperson.com/jobs/5948...</td>\n      <td>...</td>\n      <td>52.0</td>\n      <td>Finance and Insurance</td>\n      <td>522.0</td>\n      <td>Credit Intermediation and Related Activities</td>\n      <td>5221.0</td>\n      <td>Depository Credit Intermediation</td>\n      <td>52211.0</td>\n      <td>Commercial Banking</td>\n      <td>522110.0</td>\n      <td>Commercial Banking</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>cb5ca25f02bdf25c13edfede7931508bfd9e858f</td>\n      <td>6/19/2024</td>\n      <td>2024-06-19 07:00:00.000 Z</td>\n      <td>0.0</td>\n      <td>6/2/2024</td>\n      <td>6/17/2024</td>\n      <td>15.0</td>\n      <td>[\\n  \"FreeJobBoard\"\\n]</td>\n      <td>[\\n  \"craigslist.org\"\\n]</td>\n      <td>[\\n  \"https://modesto.craigslist.org/sls/77475...</td>\n      <td>...</td>\n      <td>99.0</td>\n      <td>Unclassified Industry</td>\n      <td>999.0</td>\n      <td>Unclassified Industry</td>\n      <td>9999.0</td>\n      <td>Unclassified Industry</td>\n      <td>99999.0</td>\n      <td>Unclassified Industry</td>\n      <td>999999.0</td>\n      <td>Unclassified Industry</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 131 columns</p>\n</div>\n```\n:::\n:::\n\n\n::: {#data-inspection .cell execution_count=29}\n``` {.python .cell-code}\n# Check data quality\nprint(\"=\"*80)\nprint(\"DATA QUALITY ASSESSMENT\")\nprint(\"=\"*80)\n\n# Key columns for analysis\nkey_columns = ['SALARY', 'STATE', 'TITLE', 'NAICS_2022_2', 'SOC_2', 'ONET', 'LIGHTCAST_SECTORS']\n\ninfo_df = pd.DataFrame({\n    'Column': key_columns,\n    'Missing': [df[col].isnull().sum() if col in df.columns else 'N/A' for col in key_columns],\n    'Missing %': [f\"{(df[col].isnull().sum() / len(df) * 100):.2f}%\" if col in df.columns else 'N/A' for col in key_columns],\n    'Unique Values': [df[col].nunique() if col in df.columns else 'N/A' for col in key_columns]\n})\n\nprint(info_df.to_string(index=False))\n\n# Salary statistics\nif 'SALARY' in df.columns:\n    print(f\"\\nSalary Statistics:\")\n    print(f\"  Mean: ${df['SALARY'].mean():,.2f}\")\n    print(f\"  Median: ${df['SALARY'].median():,.2f}\")\n    print(f\"  Std Dev: ${df['SALARY'].std():,.2f}\")\n    print(f\"  Range: ${df['SALARY'].min():,.2f} - ${df['SALARY'].max():,.2f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n================================================================================\nDATA QUALITY ASSESSMENT\n================================================================================\n           Column  Missing Missing %  Unique Values\n           SALARY    41690    57.51%           6052\n            STATE       44     0.06%             51\n            TITLE       44     0.06%           5719\n     NAICS_2022_2       44     0.06%             21\n            SOC_2       44     0.06%              1\n             ONET       44     0.06%              1\nLIGHTCAST_SECTORS    54711    75.47%             23\n\nSalary Statistics:\n  Mean: $117,953.76\n  Median: $116,300.00\n  Std Dev: $45,133.88\n  Range: $15,860.00 - $500,000.00\n```\n:::\n:::\n\n\n## Data Preprocessing\n\n::: {#preprocessing .cell execution_count=30}\n``` {.python .cell-code}\n# Create working copy\ndf_clean = df.copy()\n\n# Remove rows with missing salary or state\nrequired_cols = ['SALARY', 'STATE']\ninitial_rows = len(df_clean)\ndf_clean = df_clean.dropna(subset=required_cols)\nremoved_rows = initial_rows - len(df_clean)\n\nprint(f\"Removed {removed_rows:,} rows with missing salary or state data\")\nprint(f\"Final dataset: {len(df_clean):,} rows\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRemoved 41,690 rows with missing salary or state data\nFinal dataset: 30,808 rows\n```\n:::\n:::\n\n\n::: {.cell execution_count=31}\n``` {.python .cell-code}\n## Political Leaning Classification (Fixed)\n\n#| label: fix-fips-and-political-leaning\n#| code-fold: true\n\n# FIPS code to state abbreviation mapping\nfips_to_state = {\n    1: 'AL', 2: 'AK', 4: 'AZ', 5: 'AR', 6: 'CA', 8: 'CO', 9: 'CT', 10: 'DE',\n    11: 'DC', 12: 'FL', 13: 'GA', 15: 'HI', 16: 'ID', 17: 'IL', 18: 'IN',\n    19: 'IA', 20: 'KS', 21: 'KY', 22: 'LA', 23: 'ME', 24: 'MD', 25: 'MA',\n    26: 'MI', 27: 'MN', 28: 'MS', 29: 'MO', 30: 'MT', 31: 'NE', 32: 'NV',\n    33: 'NH', 34: 'NJ', 35: 'NM', 36: 'NY', 37: 'NC', 38: 'ND', 39: 'OH',\n    40: 'OK', 41: 'OR', 42: 'PA', 44: 'RI', 45: 'SC', 46: 'SD', 47: 'TN',\n    48: 'TX', 49: 'UT', 50: 'VT', 51: 'VA', 53: 'WA', 54: 'WV', 55: 'WI',\n    56: 'WY', 72: 'PR'\n}\n\n# Convert FIPS codes to state abbreviations\ndf_clean['STATE_ABBREV'] = df_clean['STATE'].apply(\n    lambda x: fips_to_state.get(int(x), 'Unknown') if pd.notna(x) else 'Unknown'\n)\n\n# Political classifications\nred_states = ['AL', 'AK', 'AR', 'FL', 'ID', 'IN', 'IA', 'KS', 'KY', \n              'LA', 'MS', 'MO', 'MT', 'NE', 'ND', 'OH', 'OK', 'SC', \n              'SD', 'TN', 'TX', 'UT', 'WV', 'WY']\n\nblue_states = ['CA', 'CO', 'CT', 'DE', 'HI', 'IL', 'ME', 'MD', 'MA', \n               'MI', 'MN', 'NH', 'NJ', 'NM', 'NY', 'OR', 'PA', 'RI', \n               'VT', 'VA', 'WA', 'WI', 'DC']\n\nswing_states = ['AZ', 'GA', 'NC', 'NV']\n\ndef assign_political_leaning(state_abbrev):\n    if pd.isna(state_abbrev) or state_abbrev == 'Unknown':\n        return 'Unknown'\n    state_abbrev = str(state_abbrev).upper()\n    if state_abbrev in red_states:\n        return 'Red'\n    elif state_abbrev in blue_states:\n        return 'Blue'\n    elif state_abbrev in swing_states:\n        return 'Swing'\n    else:\n        return 'Other'\n\ndf_clean['political_leaning'] = df_clean['STATE_ABBREV'].apply(assign_political_leaning)\n\nprint(\"=\"*60)\nprint(\"POLITICAL LEANING DISTRIBUTION (FIXED)\")\nprint(\"=\"*60)\nprint(df_clean['political_leaning'].value_counts())\nprint(\"\\nPercentage:\")\nprint((df_clean['political_leaning'].value_counts() / len(df_clean) * 100).round(2))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n============================================================\nPOLITICAL LEANING DISTRIBUTION (FIXED)\n============================================================\npolitical_leaning\nBlue     17798\nRed      10212\nSwing     2798\nName: count, dtype: int64\n\nPercentage:\npolitical_leaning\nBlue     57.77\nRed      33.15\nSwing     9.08\nName: count, dtype: float64\n```\n:::\n:::\n\n\n::: {#visualize-political-distribution .cell execution_count=32}\n``` {.python .cell-code code-fold=\"true\"}\n# Visualize political leaning distribution\nfig = px.pie(\n    values=df_clean['political_leaning'].value_counts().values,\n    names=df_clean['political_leaning'].value_counts().index,\n    title='Distribution of Jobs by Political Leaning of State',\n    hole=0.4,\n    color_discrete_map={'Red': '#FF6B6B', 'Blue': '#4ECDC4', 'Swing': '#FFD93D', 'Other': '#95A5A6'}\n)\nfig.update_layout(template=\"plotly_white\", height=400)\nfig.show()\n\nfig.write_html(\"./output/visualize_political_distribution.html\")\n```\n\n::: {#visualize-political-distribution-1 .cell-output .cell-output-display}\n```\nUnable to display output for mime type(s): text/html\n```\n:::\n\n::: {#visualize-political-distribution-2 .cell-output .cell-output-display}\n```\nUnable to display output for mime type(s): text/html\n```\n:::\n:::\n\n\n```{=html}\n<iframe width=\"900\" height=\"650\" src=\"./output/visualize_political_distribution.html\" title=\"Distribution of Jobs by Political Leaning of State\"></iframe>\n```\n\n## K-Means Clustering (unsupervised)\n\n### Setup and Feature Engineering\n\n::: {#clustering-reference-label .cell execution_count=33}\n``` {.python .cell-code code-fold=\"true\"}\n# Determine which reference label to use (SOC, NAICS, or ONET)\nreference_label = None\nfor label in ['SOC_2', 'NAICS_2022_2', 'ONET', 'LIGHTCAST_SECTORS']:\n    if label in df_clean.columns and df_clean[label].notna().sum() > 0:\n        reference_label = label\n        print(f\"✓ Using {label} as reference label\")\n        break\n\nif reference_label is None:\n    print(\"No classification column found. Using TITLE as reference.\")\n    reference_label = 'TITLE'\n\nprint(f\"\\nReference Label: {reference_label}\")\nprint(f\"Unique values: {df_clean[reference_label].nunique():,}\")\nprint(f\"\\nTop 10 {reference_label} categories:\")\nprint(df_clean[reference_label].value_counts().head(10))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n✓ Using SOC_2 as reference label\n\nReference Label: SOC_2\nUnique values: 1\n\nTop 10 SOC_2 categories:\nSOC_2\n15-0000    30808\nName: count, dtype: int64\n```\n:::\n:::\n\n\n::: {#clustering-feature-engineering .cell execution_count=34}\n``` {.python .cell-code code-fold=\"true\" code-summary=\"View feature engineering code\"}\n# Prepare features for clustering\ndf_cluster = df_clean.copy()\n\nprint(\"=\"*80)\nprint(\"FEATURE ENGINEERING FOR CLUSTERING\")\nprint(\"=\"*80)\n\n# Encode categorical variables\nencoders = {}\ncategorical_cols = ['STATE', 'TITLE', 'political_leaning', 'LIGHTCAST_SECTORS']\n\nprint(f\"\\nEncoding categorical variables:\")\nfor col in categorical_cols:\n    if col in df_cluster.columns:\n        le = LabelEncoder()\n        df_cluster[f'{col}_encoded'] = le.fit_transform(\n            df_cluster[col].fillna('Unknown').astype(str)\n        )\n        encoders[col] = le\n        print(f\"  ✓ {col}: {df_cluster[col].nunique()} unique values\")\n\n# Select clustering features\nclustering_features = ['SALARY']\n\nfor col in categorical_cols:\n    encoded_col = f'{col}_encoded'\n    if encoded_col in df_cluster.columns:\n        clustering_features.append(encoded_col)\n\n# Add years of experience if available\nif 'MIN_YEARS_EXPERIENCE' in df_cluster.columns:\n    df_cluster['MIN_YEARS_EXPERIENCE'] = pd.to_numeric(\n        df_cluster['MIN_YEARS_EXPERIENCE'], errors='coerce'\n    )\n    clustering_features.append('MIN_YEARS_EXPERIENCE')\n    print(f\"  ✓ MIN_YEARS_EXPERIENCE: numeric feature\")\n\nprint(f\"\\n📊 Total Clustering Features: {len(clustering_features)}\")\nprint(\"\\nFeature List:\")\nfor i, feature in enumerate(clustering_features, 1):\n    print(f\"  {i}. {feature}\")\n\n# Prepare feature matrix\nX_cluster = df_cluster[clustering_features].fillna(df_cluster[clustering_features].mean())\nprint(f\"\\nFeature Matrix Shape: {X_cluster.shape}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n================================================================================\nFEATURE ENGINEERING FOR CLUSTERING\n================================================================================\n\nEncoding categorical variables:\n  ✓ STATE: 51 unique values\n  ✓ TITLE: 3286 unique values\n  ✓ political_leaning: 3 unique values\n  ✓ LIGHTCAST_SECTORS: 23 unique values\n  ✓ MIN_YEARS_EXPERIENCE: numeric feature\n\n📊 Total Clustering Features: 6\n\nFeature List:\n  1. SALARY\n  2. STATE_encoded\n  3. TITLE_encoded\n  4. political_leaning_encoded\n  5. LIGHTCAST_SECTORS_encoded\n  6. MIN_YEARS_EXPERIENCE\n\nFeature Matrix Shape: (30808, 6)\n```\n:::\n:::\n\n\n### Determine Optimal K\n\n::: {#determine-optimal-clusters .cell execution_count=35}\n``` {.python .cell-code code-fold=\"true\" code-summary=\"View elbow method code\"}\n# Standardize features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X_cluster)\n\n# Test different numbers of clusters\nK_range = range(2, 11)\ninertias = []\nsilhouette_scores = []\n\nprint(\"Testing different numbers of clusters...\")\nprint(f\"{'k':<5} {'Inertia':<15} {'Silhouette Score'}\")\nprint(\"-\" * 40)\n\nfor k in K_range:\n    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n    kmeans.fit(X_scaled)\n    inertias.append(kmeans.inertia_)\n    sil_score = silhouette_score(X_scaled, kmeans.labels_)\n    silhouette_scores.append(sil_score)\n    print(f\"{k:<5} {kmeans.inertia_:<15.2f} {sil_score:.4f}\")\n\noptimal_k = list(K_range)[silhouette_scores.index(max(silhouette_scores))]\nprint(f\"\\n💡 Optimal k based on Silhouette Score: {optimal_k}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTesting different numbers of clusters...\nk     Inertia         Silhouette Score\n----------------------------------------\n2     154056.48       0.2204\n3     131383.22       0.1936\n4     115316.04       0.1890\n5     103986.36       0.1827\n6     97630.31        0.1782\n7     92195.28        0.1813\n8     86787.56        0.1753\n9     82257.94        0.1792\n10    78108.55        0.1882\n\n💡 Optimal k based on Silhouette Score: 2\n```\n:::\n:::\n\n\n::: {.cell execution_count=36}\n``` {.python .cell-code code-fold=\"true\"}\n# Visualize elbow curve and silhouette scores\nfig = make_subplots(\n    rows=1, cols=2,\n    subplot_titles=('Elbow Method', 'Silhouette Score Method')\n)\n\nfig.add_trace(\n    go.Scatter(x=list(K_range), y=inertias, mode='lines+markers', \n               name='Inertia', line=dict(color='blue')),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=list(K_range), y=silhouette_scores, mode='lines+markers', \n               name='Silhouette', line=dict(color='orange')),\n    row=1, col=2\n)\n\nfig.update_xaxes(title_text=\"Number of Clusters (k)\", row=1, col=1)\nfig.update_xaxes(title_text=\"Number of Clusters (k)\", row=1, col=2)\nfig.update_yaxes(title_text=\"Inertia\", row=1, col=1)\nfig.update_yaxes(title_text=\"Silhouette Score\", row=1, col=2)\n\nfig.update_layout(\n    height=400, \n    showlegend=False, \n    template=\"plotly_white\",\n    title_text=\"Determining Optimal Number of Clusters\"\n)\nfig.show()\n\nfig.write_html(\"./output/elbow_curve.html\")\n```\n\n::: {#plot-elbow-silhouette .cell-output .cell-output-display}\n```\nUnable to display output for mime type(s): text/html\n```\n:::\n:::\n\n\n```{=html}\n<iframe width=\"900\" height=\"650\" src=\"./output/elbow_curve.html\" title=\"Elbow Curve and Silhouette Score\"></iframe>\n```\n\n\n### Cluster Analysis\n\n::: {#perform-kmeans .cell execution_count=37}\n``` {.python .cell-code code-fold=\"true\"}\n# Perform KMeans with k=5 (per assignment requirements)\nn_clusters = 5\n\nprint(f\"Performing KMeans with k={n_clusters} clusters...\")\nkmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\ndf_cluster['cluster'] = kmeans.fit_predict(X_scaled)\n\nprint(f\"✓ Clustering complete!\")\nprint(f\"\\nCluster Distribution:\")\ncluster_counts = df_cluster['cluster'].value_counts().sort_index()\nfor cluster_id, count in cluster_counts.items():\n    pct = (count / len(df_cluster)) * 100\n    print(f\"  Cluster {cluster_id}: {count:,} jobs ({pct:.1f}%)\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPerforming KMeans with k=5 clusters...\n✓ Clustering complete!\n\nCluster Distribution:\n  Cluster 0: 8,137 jobs (26.4%)\n  Cluster 1: 5,007 jobs (16.3%)\n  Cluster 2: 5,208 jobs (16.9%)\n  Cluster 3: 6,211 jobs (20.2%)\n  Cluster 4: 6,245 jobs (20.3%)\n```\n:::\n:::\n\n\n::: {.cell execution_count=38}\n``` {.python .cell-code code-fold=\"true\"}\n# Sample for performance (5000 points)\nsample_size = min(5000, len(df_cluster))\ndf_sample = df_cluster.sample(sample_size, random_state=42)\n\nfig = px.scatter(\n    df_sample,\n    x='SALARY',\n    y='STATE_encoded',\n    color='cluster',\n    hover_data=['TITLE', 'political_leaning', reference_label] if 'TITLE' in df_sample.columns else None,\n    title=f'KMeans Clustering Results (k={n_clusters}, n={sample_size:,} sample)',\n    labels={'SALARY': 'Annual Salary ($)', 'STATE_encoded': 'State (Encoded)', 'cluster': 'Cluster'},\n    color_continuous_scale='Viridis'\n)\nfig.update_layout(template=\"plotly_white\", height=550, font=dict(family=\"Roboto\", size=12))\nfig.show()\n\nfig.write_html(\"./output/clusters.html\")\n```\n\n::: {#visualize-clusters .cell-output .cell-output-display}\n```\nUnable to display output for mime type(s): text/html\n```\n:::\n:::\n\n\n```{=html}\n<iframe width=\"900\" height=\"650\" src=\"./output/clusters.html\" title=\"Clusters\"></iframe>\n```\n\n\n\n**Key Findings:**\n- Cluster 0: Entry-level positions ($50-100k)\n- Cluster 4: Senior roles ($200k+)\n- Geographic clustering evident by state encoding\n\n::: {#cluster-profiling .cell execution_count=39}\n``` {.python .cell-code code-fold=\"true\"}\n# Analyze cluster characteristics\nprint(\"=\"*80)\nprint(\"CLUSTER PROFILES\")\nprint(\"=\"*80)\n\ncluster_profiles = df_cluster.groupby('cluster').agg({\n    'SALARY': ['mean', 'median', 'std', 'min', 'max'],\n    'political_leaning': lambda x: x.mode()[0] if len(x.mode()) > 0 else 'Mixed',\n    'cluster': 'count'\n})\n\ncluster_profiles.columns = [\n    'Avg_Salary', 'Median_Salary', 'Salary_StdDev', 'Min_Salary', 'Max_Salary',\n    'Dominant_Political', 'Count'\n]\n\ncluster_profiles = cluster_profiles.round(2)\nprint(cluster_profiles)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n================================================================================\nCLUSTER PROFILES\n================================================================================\n         Avg_Salary  Median_Salary  Salary_StdDev  Min_Salary  Max_Salary  \\\ncluster                                                                     \n0          97442.86        95000.0       33748.50     21237.0    250000.0   \n1         170814.08       166500.0       42553.06     77050.0    500000.0   \n2         103140.74       100000.0       39435.72     15860.0    264976.0   \n3         111217.04       110000.0       39249.52     20800.0    275000.0   \n4         121350.62       119300.0       35456.33     23585.0    305000.0   \n\n        Dominant_Political  Count  \ncluster                            \n0                     Blue   8137  \n1                     Blue   5007  \n2                      Red   5208  \n3                     Blue   6211  \n4                     Blue   6245  \n```\n:::\n:::\n\n\n::: {.cell execution_count=40}\n``` {.python .cell-code code-fold=\"true\"}\n# Visualize cluster salary profiles\nprofile_df = cluster_profiles.reset_index()\n\nfig = px.bar(\n    profile_df,\n    x='cluster',\n    y='Avg_Salary',\n    text='Count',\n    title='Average Salary by Cluster',\n    labels={'cluster': 'Cluster', 'Avg_Salary': 'Average Salary ($)'},\n    color='Avg_Salary',\n    color_continuous_scale='Viridis'\n)\nfig.update_traces(texttemplate='n=%{text:,}', textposition='outside')\nfig.update_layout(template=\"plotly_white\", height=450, font=dict(family=\"Roboto\", size=12))\nfig.show()\n\nfig.write_html(\"./output/cluster_profiles.html\")\n```\n\n::: {#visualize-cluster-profiles .cell-output .cell-output-display}\n```\nUnable to display output for mime type(s): text/html\n```\n:::\n:::\n\n\n```{=html}\n<iframe width=\"900\" height=\"650\" src=\"./output/cluster_profiles.html\" title=\"Cluster Profiles\"></iframe>\n```\n\n::: {#cluster-reference-comparison .cell execution_count=41}\n``` {.python .cell-code code-fold=\"true\"}\n# Compare clusters with reference labels\nprint(f\"\\n{'='*80}\")\nprint(f\"CLUSTER vs {reference_label.upper()} COMPARISON\")\nprint(f\"{'='*80}\")\n\nfor cluster_id in sorted(df_cluster['cluster'].unique()):\n    cluster_data = df_cluster[df_cluster['cluster'] == cluster_id]\n    top_categories = cluster_data[reference_label].value_counts().head(5)\n    \n    print(f\"\\n📊 Cluster {cluster_id}:\")\n    print(f\"   Size: {len(cluster_data):,} jobs\")\n    print(f\"   Avg Salary: ${cluster_data['SALARY'].mean():,.2f}\")\n    if 'political_leaning' in cluster_data.columns:\n        print(f\"   Dominant Political: {cluster_data['political_leaning'].mode()[0] if len(cluster_data['political_leaning'].mode()) > 0 else 'Mixed'}\")\n    print(f\"   Top 5 {reference_label} categories:\")\n    for category, count in top_categories.items():\n        pct = (count / len(cluster_data)) * 100\n        print(f\"     • {category}: {count:,} ({pct:.1f}%)\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n================================================================================\nCLUSTER vs SOC_2 COMPARISON\n================================================================================\n\n📊 Cluster 0:\n   Size: 8,137 jobs\n   Avg Salary: $97,442.86\n   Dominant Political: Blue\n   Top 5 SOC_2 categories:\n     • 15-0000: 8,137 (100.0%)\n\n📊 Cluster 1:\n   Size: 5,007 jobs\n   Avg Salary: $170,814.08\n   Dominant Political: Blue\n   Top 5 SOC_2 categories:\n     • 15-0000: 5,007 (100.0%)\n\n📊 Cluster 2:\n   Size: 5,208 jobs\n   Avg Salary: $103,140.74\n   Dominant Political: Red\n   Top 5 SOC_2 categories:\n     • 15-0000: 5,208 (100.0%)\n\n📊 Cluster 3:\n   Size: 6,211 jobs\n   Avg Salary: $111,217.04\n   Dominant Political: Blue\n   Top 5 SOC_2 categories:\n     • 15-0000: 6,211 (100.0%)\n\n📊 Cluster 4:\n   Size: 6,245 jobs\n   Avg Salary: $121,350.62\n   Dominant Political: Blue\n   Top 5 SOC_2 categories:\n     • 15-0000: 6,245 (100.0%)\n```\n:::\n:::\n\n\n## Multiple Regression Analysis\n\n::: {#regression-feature-engineering .cell execution_count=42}\n``` {.python .cell-code code-fold=\"true\" code-summary=\"View feature engineering code\"}\n# Prepare features for salary prediction\ndf_reg = df_clean.copy()\n\nprint(\"=\"*80)\nprint(\"FEATURE ENGINEERING FOR SALARY PREDICTION\")\nprint(\"=\"*80)\n\n# Encode categorical variables\nle_reg = {}\ncategorical_features = ['STATE', 'TITLE', 'political_leaning', 'LIGHTCAST_SECTORS']\n\n# Add SOC or NAICS if available\nif 'SOC_2' in df_reg.columns:\n    categorical_features.append('SOC_2')\nelif 'NAICS_2022_2' in df_reg.columns:\n    categorical_features.append('NAICS_2022_2')\n\nprint(f\"\\nCategorical features to encode ({len(categorical_features)}):\")\nfor col in categorical_features:\n    if col in df_reg.columns:\n        le = LabelEncoder()\n        df_reg[f'{col}_encoded'] = le.fit_transform(\n            df_reg[col].fillna('Unknown').astype(str)\n        )\n        le_reg[col] = le\n        print(f\"  ✓ {col}: {df_reg[col].nunique()} unique values\")\n\n# Select features for regression\nfeature_cols = []\nfor col in categorical_features:\n    encoded_col = f'{col}_encoded'\n    if encoded_col in df_reg.columns:\n        feature_cols.append(encoded_col)\n\n# Add numerical features if available\nnumeric_features = ['MIN_YEARS_EXPERIENCE', 'MAX_YEARS_EXPERIENCE']\nfor num_feat in numeric_features:\n    if num_feat in df_reg.columns:\n        df_reg[num_feat] = pd.to_numeric(df_reg[num_feat], errors='coerce')\n        if df_reg[num_feat].notna().sum() > 0:\n            feature_cols.append(num_feat)\n            print(f\"  ✓ {num_feat}: numeric feature added\")\n\nprint(f\"\\n Total Features for Salary Prediction: {len(feature_cols)}\")\n\n# Prepare X and y\nX = df_reg[feature_cols].fillna(df_reg[feature_cols].mean())\ny = df_reg['SALARY']\n\nprint(f\"\\n Dataset Statistics:\")\nprint(f\"  • Feature Matrix Shape: {X.shape}\")\nprint(f\"  • Salary Statistics:\")\nprint(f\"    - Mean: ${y.mean():,.2f}\")\nprint(f\"    - Median: ${y.median():,.2f}\")\nprint(f\"    - Std Dev: ${y.std():,.2f}\")\nprint(f\"    - Range: ${y.min():,.2f} - ${y.max():,.2f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n================================================================================\nFEATURE ENGINEERING FOR SALARY PREDICTION\n================================================================================\n\nCategorical features to encode (5):\n  ✓ STATE: 51 unique values\n  ✓ TITLE: 3286 unique values\n  ✓ political_leaning: 3 unique values\n  ✓ LIGHTCAST_SECTORS: 23 unique values\n  ✓ SOC_2: 1 unique values\n  ✓ MIN_YEARS_EXPERIENCE: numeric feature added\n  ✓ MAX_YEARS_EXPERIENCE: numeric feature added\n\n Total Features for Salary Prediction: 7\n\n Dataset Statistics:\n  • Feature Matrix Shape: (30808, 7)\n  • Salary Statistics:\n    - Mean: $117,953.76\n    - Median: $116,300.00\n    - Std Dev: $45,133.88\n    - Range: $15,860.00 - $500,000.00\n```\n:::\n:::\n\n\nFeature Selection Justification:\nThe features were selected based on their theoretical and empirical relationship with salary:\n\nSTATE & Political Leaning: Geographic location and political climate influence cost of living and compensation policies\nTITLE: Job title is the primary indicator of role level and responsibility\nLIGHTCAST_SECTORS: Industry sector determines baseline compensation structure\nSOC/NAICS: Occupation classification provides standardized job categorization\nYears of Experience: Direct correlation with salary progression (if available)\n\n::: {#train-test-split-regression .cell execution_count=43}\n``` {.python .cell-code code-fold=\"true\"}\n# Split data (70/30 as per assignment requirements)\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.30, random_state=42\n)\n\nprint(\"=\"*80)\nprint(\"TRAIN/TEST SPLIT\")\nprint(\"=\"*80)\nprint(f\"\\nTraining Set: {X_train.shape[0]:,} samples ({X_train.shape[0]/len(X)*100:.1f}%)\")\nprint(f\"Test Set: {X_test.shape[0]:,} samples ({X_test.shape[0]/len(X)*100:.1f}%)\")\nprint(f\"\\nSalary Distribution:\")\nprint(f\"  Training - Mean: ${y_train.mean():,.2f}, Std: ${y_train.std():,.2f}\")\nprint(f\"  Test - Mean: ${y_test.mean():,.2f}, Std: ${y_test.std():,.2f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n================================================================================\nTRAIN/TEST SPLIT\n================================================================================\n\nTraining Set: 21,565 samples (70.0%)\nTest Set: 9,243 samples (30.0%)\n\nSalary Distribution:\n  Training - Mean: $117,747.63, Std: $45,170.79\n  Test - Mean: $118,434.66, Std: $45,046.43\n```\n:::\n:::\n\n\n::: {#multiple-linear-regression .cell execution_count=44}\n``` {.python .cell-code code-fold=\"true\" code-summary=\"View Linear Regression code\"}\nprint(\"=\"*80)\nprint(\"MODEL 1: MULTIPLE LINEAR REGRESSION\")\nprint(\"=\"*80)\n\n# Train model\nlin_reg = LinearRegression()\nlin_reg.fit(X_train, y_train)\n\n# Make predictions\ny_pred_lin = lin_reg.predict(X_test)\n\n# Calculate evaluation metrics\nrmse_lin = np.sqrt(mean_squared_error(y_test, y_pred_lin))\nr2_lin = r2_score(y_test, y_pred_lin)\nmae_lin = np.mean(np.abs(y_test - y_pred_lin))\n\nprint(f\"\\n📊 Model Performance:\")\nprint(f\"   • R² Score: {r2_lin:.4f}\")\nprint(f\"     → Explains {r2_lin*100:.2f}% of salary variance\")\nprint(f\"   • RMSE: ${rmse_lin:,.2f}\")\nprint(f\"   • MAE: ${mae_lin:,.2f}\")\n\n# Feature coefficients\ncoef_df = pd.DataFrame({\n    'Feature': feature_cols,\n    'Coefficient': lin_reg.coef_\n}).sort_values('Coefficient', key=abs, ascending=False)\n\nprint(f\"\\n📈 Top 10 Most Influential Features:\")\nprint(coef_df.head(10).to_string(index=False))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n================================================================================\nMODEL 1: MULTIPLE LINEAR REGRESSION\n================================================================================\n\n📊 Model Performance:\n   • R² Score: 0.2106\n     → Explains 21.06% of salary variance\n   • RMSE: $40,021.31\n   • MAE: $31,035.39\n\n📈 Top 10 Most Influential Features:\n                  Feature   Coefficient\n     MIN_YEARS_EXPERIENCE  6.266993e+03\npolitical_leaning_encoded -4.017884e+03\n     MAX_YEARS_EXPERIENCE  2.308933e+03\nLIGHTCAST_SECTORS_encoded  4.382554e+02\n            STATE_encoded  3.158638e+01\n            TITLE_encoded  3.020147e+00\n            SOC_2_encoded  1.909939e-11\n```\n:::\n:::\n\n\n::: {.cell execution_count=45}\n``` {.python .cell-code code-fold=\"true\"}\n# Visualize top 15 feature coefficients\ntop_features = coef_df.head(15)\n\nfig = px.bar(\n    top_features,\n    x='Coefficient',\n    y='Feature',\n    orientation='h',\n    title='Top 15 Feature Coefficients - Multiple Linear Regression',\n    labels={'Coefficient': 'Impact on Salary ($)', 'Feature': 'Feature'},\n    color='Coefficient',\n    color_continuous_scale='RdBu',\n    color_continuous_midpoint=0\n)\n\nfig.update_layout(template=\"plotly_white\", height=500, font=dict(family=\"Roboto\", size=12))\nfig.show()\n\nfig.write_html(\"./output/linear_coefficients.html\")\n```\n\n::: {#visualize-linear-coefficients .cell-output .cell-output-display}\n```\nUnable to display output for mime type(s): text/html\n```\n:::\n:::\n\n\n```{=html}\n<iframe width=\"900\" height=\"650\" src=\"./output/linear_coefficients.html\" title=\"Linear Coefficients\"></iframe>\n```\n\n::: {#random-forest-regression .cell execution_count=46}\n``` {.python .cell-code code-fold=\"true\" code-summary=\"View Random Forest code\"}\nprint(\"=\"*80)\nprint(\"MODEL 2: RANDOM FOREST REGRESSION\")\nprint(\"=\"*80)\n\n# Train model\nrf_reg = RandomForestRegressor(\n    n_estimators=100,\n    max_depth=20,\n    min_samples_split=10,\n    min_samples_leaf=4,\n    random_state=42,\n    n_jobs=-1\n)\n\nprint(\"Training Random Forest model...\")\nrf_reg.fit(X_train, y_train)\nprint(\"✓ Training complete!\")\n\n# Make predictions\ny_pred_rf = rf_reg.predict(X_test)\n\n# Calculate evaluation metrics\nrmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))\nr2_rf = r2_score(y_test, y_pred_rf)\nmae_rf = np.mean(np.abs(y_test - y_pred_rf))\n\nprint(f\"\\n Model Performance:\")\nprint(f\"   • R² Score: {r2_rf:.4f}\")\nprint(f\"     → Explains {r2_rf*100:.2f}% of salary variance\")\nprint(f\"   • RMSE: ${rmse_rf:,.2f}\")\nprint(f\"   • MAE: ${mae_rf:,.2f}\")\n\n# Feature importance\nimportance_df = pd.DataFrame({\n    'Feature': feature_cols,\n    'Importance': rf_reg.feature_importances_\n}).sort_values('Importance', ascending=False)\n\nprint(f\"\\n Top 10 Most Important Features:\")\nprint(importance_df.head(10).to_string(index=False))\n\n# Calculate improvement safely\nif r2_lin > 0:\n    improvement = ((r2_rf - r2_lin) / r2_lin) * 100\n    print(f\"\\n🚀 Random Forest improves R² by {improvement:.1f}% over Linear Regression\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n================================================================================\nMODEL 2: RANDOM FOREST REGRESSION\n================================================================================\nTraining Random Forest model...\n✓ Training complete!\n\n Model Performance:\n   • R² Score: 0.5717\n     → Explains 57.17% of salary variance\n   • RMSE: $29,478.34\n   • MAE: $20,012.05\n\n Top 10 Most Important Features:\n                  Feature  Importance\n            TITLE_encoded    0.484861\n     MIN_YEARS_EXPERIENCE    0.346083\n            STATE_encoded    0.089213\nLIGHTCAST_SECTORS_encoded    0.048833\npolitical_leaning_encoded    0.019680\n     MAX_YEARS_EXPERIENCE    0.011329\n            SOC_2_encoded    0.000000\n\n🚀 Random Forest improves R² by 171.5% over Linear Regression\n```\n:::\n:::\n\n\n::: {.cell execution_count=47}\n``` {.python .cell-code code-fold=\"true\"}\n# Visualize feature importance\ntop_features_rf = importance_df.head(15)\n\nfig = px.bar(\n    top_features_rf,\n    x='Importance',\n    y='Feature',\n    orientation='h',\n    title='Top 15 Feature Importance - Random Forest Regression',\n    labels={'Importance': 'Importance Score', 'Feature': 'Feature'},\n    color='Importance',\n    color_continuous_scale='Viridis'\n)\n\nfig.update_layout(template=\"plotly_white\", height=500, font=dict(family=\"Roboto\", size=12))\nfig.show()\n\nfig.write_html(\"./output/feature_importance.html\")\n```\n\n::: {#visualize-feature-importance .cell-output .cell-output-display}\n```\nUnable to display output for mime type(s): text/html\n```\n:::\n:::\n\n\n```{=html}\n<iframe width=\"900\" height=\"650\" src=\"./output/feature_importance.html\" title=\"Feature Importance for Random Forest Regression\"></iframe>\n```\n\n::: {#model-comparison-regression .cell execution_count=48}\n``` {.python .cell-code code-fold=\"true\"}\nprint(\"=\"*80)\nprint(\"REGRESSION MODEL COMPARISON\")\nprint(\"=\"*80)\n\n# Create comparison dataframe\ncomparison_df = pd.DataFrame({\n    'Model': ['Multiple Linear Regression', 'Random Forest Regression'],\n    'R² Score': [r2_lin, r2_rf],\n    'RMSE ($)': [rmse_lin, rmse_rf],\n    'MAE ($)': [mae_lin, mae_rf]\n})\n\nprint(\"\\n\" + comparison_df.to_string(index=False))\n\nbest_model = comparison_df.loc[comparison_df['R² Score'].idxmax(), 'Model']\nbest_r2 = comparison_df['R² Score'].max()\n\nprint(f\"\\n🏆 Best Performing Model: {best_model}\")\nprint(f\"   • Achieves R² of {best_r2:.4f}\")\nprint(f\"   • Explains {best_r2*100:.2f}% of salary variance\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n================================================================================\nREGRESSION MODEL COMPARISON\n================================================================================\n\n                     Model  R² Score     RMSE ($)      MAE ($)\nMultiple Linear Regression  0.210579 40021.308824 31035.389186\n  Random Forest Regression  0.571716 29478.338762 20012.049850\n\n🏆 Best Performing Model: Random Forest Regression\n   • Achieves R² of 0.5717\n   • Explains 57.17% of salary variance\n```\n:::\n:::\n\n\n::: {.cell execution_count=49}\n``` {.python .cell-code code-fold=\"true\"}\n# Sample for performance\nsample_size = min(2000, len(y_test))\nindices = np.random.choice(len(y_test), sample_size, replace=False)\n\ncomparison_results = pd.DataFrame({\n    'Actual': y_test.iloc[indices],\n    'Linear_Regression': y_pred_lin[indices],\n    'Random_Forest': y_pred_rf[indices]\n})\n\nfig = go.Figure()\n\n# Random Forest predictions\nfig.add_trace(go.Scatter(\n    x=comparison_results['Actual'],\n    y=comparison_results['Random_Forest'],\n    mode='markers',\n    name='Random Forest',\n    opacity=0.6,\n    marker=dict(size=5, color='blue')\n))\n\n# Linear Regression predictions\nfig.add_trace(go.Scatter(\n    x=comparison_results['Actual'],\n    y=comparison_results['Linear_Regression'],\n    mode='markers',\n    name='Linear Regression',\n    opacity=0.6,\n    marker=dict(size=5, color='red')\n))\n\n# Perfect prediction line\nmin_val = comparison_results['Actual'].min()\nmax_val = comparison_results['Actual'].max()\n\nfig.add_trace(go.Scatter(\n    x=[min_val, max_val],\n    y=[min_val, max_val],\n    mode='lines',\n    name='Perfect Prediction',\n    line=dict(color='green', dash='dash', width=2)\n))\n\nfig.update_layout(\n    title=f'Actual vs Predicted Salary - Model Comparison (n={sample_size:,})',\n    xaxis_title='Actual Salary ($)',\n    yaxis_title='Predicted Salary ($)',\n    template=\"plotly_white\",\n    height=550,\n    hovermode='closest'\n)\n\nfig.show()\n\nfig.write_html(\"./output/model_comparison.html\")\n```\n\n::: {#predictions-vs-actual .cell-output .cell-output-display}\n```\nUnable to display output for mime type(s): text/html\n```\n:::\n:::\n\n\n```{=html}\n<iframe width=\"900\" height=\"650\" src=\"./output/model_comparison.html\" title=\"Model Comparison\"></iframe>\n```\n\n",
    "supporting": [
      "final_report_files"
    ],
    "filters": []
  }
}