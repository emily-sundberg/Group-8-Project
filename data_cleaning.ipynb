{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Data Cleaning\"\n",
        "---"
      ],
      "id": "7572639c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load the dataset\n"
      ],
      "id": "4ddc01bd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.io as pio\n",
        "from pyspark.sql import SparkSession\n",
        "import re\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "from pyspark.sql.functions import col, split, explode, regexp_replace, transform, when\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.functions import col, monotonically_increasing_id\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "pio.renderers.default = \"notebook\"\n",
        "\n",
        "spark = SparkSession.builder.appName(\"LightcastData\").getOrCreate()\n",
        "\n",
        "jobs_df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"multiLine\",\"true\").option(\"escape\", \"\\\"\").csv(\"./data/lightcast_job_postings.csv\")\n",
        "jobs_df.createOrReplaceTempView(\"job_postings\")\n",
        "\n",
        "elections_df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"multiLine\",\"true\").option(\"escape\", \"\\\"\").csv(\"./data/2024_election_results.csv\")\n",
        "elections_df.createOrReplaceTempView(\"election_results\")\n",
        "\n",
        "#print(\"---This is Diagnostic check, No need to print it in the final doc---\")\n",
        "\n",
        "#df.printSchema() # comment this line when rendering the submission\n",
        "#jobs_df.show(5)\n",
        "#elections_df.show(5)"
      ],
      "id": "5946e25d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Cleaning\n"
      ],
      "id": "f4c08105"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# casting corrected variable type\n",
        "jobs_df = jobs_df.withColumn(\"SALARY_FROM\", col (\"SALARY_FROM\").cast(\"float\"))\\\n",
        "  .withColumn(\"SALARY_TO\", col(\"SALARY_TO\").cast(\"float\")) \\\n",
        "  .withColumn(\"MAX_YEARS_EXPERIENCE\", col(\"MAX_YEARS_EXPERIENCE\").cast(\"float\"))\\\n",
        "  .withColumn(\"MIN_YEARS_EXPERIENCE\", col(\"MIN_YEARS_EXPERIENCE\").cast(\"float\"))\\\n",
        "  .withColumn(\"SALARY\", col(\"SALARY\").cast(\"float\"))\n",
        "\n",
        "# Clean Up Columns\n",
        "jobs_df = jobs_df.withColumn(\"EDUCATION_LEVELS_NAME\", regexp_replace(col(\"EDUCATION_LEVELS_NAME\"), \"[\\n\\r]\", \"\"))\n",
        "jobs_df = jobs_df.withColumn(\"SOURCE_TYPES\", regexp_replace(col(\"SOURCE_TYPES\"), \"[\\n\\r]\", \"\"))\n",
        "jobs_df = jobs_df.withColumn(\"SOURCES\", regexp_replace(col(\"SOURCES\"), \"[\\n\\r]\", \"\"))\n",
        "jobs_df = jobs_df.withColumn(\"SKILLS\", regexp_replace(col(\"SKILLS\"), \"[\\n\\r]\", \"\"))\n",
        "jobs_df = jobs_df.withColumn(\"SKILLS_NAME\", regexp_replace(col(\"SKILLS_NAME\"), \"[\\n\\r]\", \"\"))\n",
        "jobs_df = jobs_df.withColumn(\"SPECIALIZED_SKILLS_NAME\", regexp_replace(col(\"SPECIALIZED_SKILLS_NAME\"), \"[\\n\\r]\", \"\"))\n",
        "jobs_df = jobs_df.withColumn(\"CERTIFICATIONS_NAME\", regexp_replace(col(\"CERTIFICATIONS_NAME\"), \"[\\n\\r]\", \"\"))\n",
        "jobs_df = jobs_df.withColumn(\"COMMON_SKILLS_NAME\", regexp_replace(col(\"COMMON_SKILLS_NAME\"), \"[\\n\\r]\", \"\"))\n",
        "jobs_df = jobs_df.withColumn(\"SOFTWARE_SKILLS_NAME\", regexp_replace(col(\"SOFTWARE_SKILLS_NAME\"), \"[\\n\\r]\", \"\"))\n",
        "jobs_df = jobs_df.withColumn(\"CIP6_NAME\", regexp_replace(col(\"CIP6_NAME\"), \"[\\n\\r]\", \"\"))\n",
        "jobs_df = jobs_df.withColumn(\"CIP4_NAME\", regexp_replace(col(\"CIP4_NAME\"), \"[\\n\\r]\", \"\"))\n",
        "jobs_df = jobs_df.withColumn(\"CIP2_NAME\", regexp_replace(col(\"CIP2_NAME\"), \"[\\n\\r]\", \"\"))\n",
        "\n",
        "\n",
        "# Compute and impute Median Salary\n",
        "def compute_median(sdf, col_name):\n",
        "  q = sdf.approxQuantile(col_name, [0.5], 0.01)\n",
        "  return q[0] if q else None\n",
        "\n",
        "\n",
        "median_from = compute_median(jobs_df, \"SALARY_FROM\")\n",
        "median_to = compute_median(jobs_df, \"SALARY_TO\")\n",
        "median_salary = compute_median(jobs_df, \"SALARY\")\n",
        "\n",
        "print(\"Medians:\", median_from, median_to, median_salary)\n",
        "\n",
        "jobs_df = jobs_df.fillna({\n",
        "  \"SALARY_FROM\": median_from,\n",
        "  \"SALARY_TO\": median_to,\n",
        "  \"SALARY\": median_salary\n",
        "})\n",
        "\n",
        "from pyspark.sql.functions import col\n",
        "jobs_df = jobs_df.withColumn(\n",
        "    \"MIDPOINT_SALARY\",\n",
        "    (col(\"SALARY_TO\") + col(\"SALARY_FROM\")) / 2\n",
        ")\n",
        "\n",
        "# Dropping unnecessary columns\n",
        "columns_to_drop = [\n",
        "    \"ID\", \"URL\", \"ACTIVE_URLS\", \"DUPLICATES\", \"LAST_UPDATED_TIMESTAMP\",\"STATE\",\"COUNTY_OUTGOING\",\"COUNTY_INCOMMING\",\"MSA_OUTGOING\",\"MSA_INCOMING\",\n",
        "    \"NAICS2\", \"NAICS3\", \"NAICS4\", \"NAICS5\", \"NAICS6\", \"ONET\",\"ONET_2019\",\"CIP6\",\"CIP4\",\"CIP2\",\"SOC_2021_2\",\"SOC_2021_3\",\"SOC_2021_4\",\"SOC_2021_5\",\"SOC_2\", \"SOC_3\", \"SOC_4\",\"SOC_5\", \"NAICS_2022_2\",\"NAICS_2022_3\",\"NAICS_2022_4\",\"NAICS_2022_5\",\"NAICS_2022_6\",\"CITY\",\"COUNTY\",\"MSA\",\"COUNTY_INCOMING\"\n",
        "]\n",
        "jobs_df = jobs_df.drop(*columns_to_drop)\n",
        "\n",
        "# configuring remote work groups\n",
        "from pyspark.sql.functions import when, col, trim\n",
        "\n",
        "jobs_df = jobs_df.withColumn(\"REMOTE_GROUP\",\n",
        "  when(trim(col(\"REMOTE_TYPE_NAME\"))== \"Remote\", \"Remote\")\n",
        "  .when(trim(col(\"REMOTE_TYPE_NAME\"))== \"Hybrid Remote\", \"Hybrid\")\n",
        "  .when(trim(col(\"REMOTE_TYPE_NAME\"))== \"Not Remote\", \"Onsite\")\n",
        "  .when(col(\"REMOTE_TYPE_NAME\").isNull(), \"Onsite\")\n",
        "  .otherwise(\"Onsite\")\n",
        ")\n",
        "\n",
        "# dropping any duplicate postings\n",
        "jobs_df = jobs_df.dropDuplicates([\"TITLE\", \"COMPANY\", \"LOCATION\", \"POSTED\"])\n",
        "\n",
        "# handling missing data\n",
        "from pyspark.sql.functions import col, when, sum as spark_sum\n",
        "\n",
        "total_rows = jobs_df.count()\n",
        "missing_threshold = total_rows * 0.5\n",
        "null_counts = jobs_df.select([\n",
        "    (spark_sum(col(c).isNull().cast(\"int\"))).alias(c) for c in jobs_df.columns\n",
        "]).collect()[0].asDict()\n",
        "columns_to_keep = [c for c, nulls in null_counts.items() if nulls <= missing_threshold or c == \"SALARY\"]\n",
        "jobs_df = jobs_df.select(columns_to_keep)\n",
        "\n",
        "#jobs_df.show(15)"
      ],
      "id": "7c271d08",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "jobs_df = jobs_df.withColumn(\"STATE_ABBREVIATION\", F.trim(F.split(jobs_df[\"COUNTY_NAME\"], \",\").getItem(1)))\n",
        "\n",
        "jobs_alias = jobs_df.alias(\"jobs\")\n",
        "elections_alias = elections_df.alias(\"elections\")\n",
        "\n",
        "jobs_df = jobs_alias.join(\n",
        "    elections_alias,\n",
        "    F.col(\"jobs.STATE_ABBREVIATION\") == F.col(\"elections.STATE\"),\n",
        "    \"left\"\n",
        ")\n",
        "jobs_df = jobs_df.drop(F.col(\"elections.STATE\"))\n",
        "\n",
        "jobs_df = jobs_df.withColumnRenamed(\"Affiliation\", \"AFFILIATION\")\n",
        "\n",
        "#jobs_df.show(15)"
      ],
      "id": "08dd295a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "selected_df = jobs_df.select(\n",
        "  \"EDUCATION_LEVELS_NAME\",\n",
        "  \"MIN_EDULEVELS_NAME\",\n",
        "  \"EMPLOYMENT_TYPE_NAME\",\n",
        "  \"MIN_YEARS_EXPERIENCE\",\n",
        "  \"SALARY_TO\",\n",
        "  \"SALARY_FROM\",\n",
        "  \"SALARY\",\n",
        "  \"CITY_NAME\",\n",
        "  \"MSA_NAME\",\n",
        "  \"STATE_NAME\",\n",
        "  \"NAICS2_NAME\",\n",
        "  \"NAICS3_NAME\",\n",
        "  \"NAICS4_NAME\",\n",
        "  \"NAICS5_NAME\",\n",
        "  \"NAICS6_NAME\",\n",
        "  \"SKILLS_NAME\",\n",
        "  \"SPECIALIZED_SKILLS_NAME\",\n",
        "  \"CERTIFICATIONS_NAME\",\n",
        "  \"COMMON_SKILLS_NAME\",\n",
        "  \"SOFTWARE_SKILLS_NAME\",\n",
        "  \"ONET_NAME\",\n",
        "  \"LOT_CAREER_AREA_NAME\",\n",
        "  \"LOT_OCCUPATION_NAME\",\n",
        "  \"LOT_SPECIALIZED_OCCUPATION_NAME\",\n",
        "  \"LOT_OCCUPATION_GROUP_NAME\",\n",
        "  \"LOT_V6_SPECIALIZED_OCCUPATION_NAME\",\n",
        "  \"LOT_V6_OCCUPATION_NAME\",\n",
        "  \"LOT_V6_OCCUPATION_GROUP_NAME\",\n",
        "  \"LOT_V6_CAREER_AREA_NAME\",\n",
        "  \"SOC_2_NAME\",\n",
        "  \"SOC_3_NAME\",\n",
        "  \"SOC_4_NAME\",\n",
        "  \"SOC_5_NAME\",\n",
        "  \"REMOTE_GROUP\",\n",
        "  \"STATE_ABBREVIATION\",\n",
        "  \"AFFILIATION\",\n",
        "  \"MIDPOINT_SALARY\"\n",
        ")"
      ],
      "id": "1c2f3bf2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "from pyspark.sql.functions import col, sum as spark_sum, when, trim, length\n",
        "import hvplot.pandas\n",
        "\n",
        "\n",
        "df_sample = selected_df.sample(fraction = .05, seed = 42).toPandas()\n",
        "\n",
        "missing_mask = df_sample.isnull()\n",
        "\n",
        "missing_long = (\n",
        "  missing_mask.reset_index()\n",
        "  .melt(id_vars = \"index\", var_name = \"column\", value_name = \"is_missing\")\n",
        ")\n",
        "\n",
        "missing_long[\"is_missing\"] = missing_long[\"is_missing\"].astype(int)\n",
        "\n",
        "missing_long.hvplot.heatmap(\n",
        "  x=\"column\",\n",
        "  y=\"index\",\n",
        "  C = \"is_missing\",\n",
        "  cmap = \"Blues\",\n",
        "  width = 900,\n",
        "  height = 500,\n",
        "  title = \"Heatmap of Missing Values (5%)\"\n",
        ").opts(xrotation=45)"
      ],
      "id": "b40e59ac",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pyspark.sql.functions import countDistinct\n",
        "\n",
        "selected_df.select([\n",
        "  countDistinct(c).alias(c+\"_nunique\")\n",
        "  for c in selected_df.columns\n",
        "]).show(truncate=False)\n",
        "\n",
        "# Education Levels\n",
        "\n",
        "selected_df = selected_df.withColumn(\n",
        "  \"EDUCATION_LEVELS_NAME\",\n",
        "    when(col(\"EDUCATION_LEVELS_NAME\").isNull(), \"No Education Listed\")\n",
        "    .otherwise(col(\"EDUCATION_LEVELS_NAME\"))\n",
        ")\n",
        "\n",
        "# Min Edu Levels\n",
        "\n",
        "selected_df = selected_df.withColumn(\n",
        "  \"MIN_EDULEVELS_NAME\",\n",
        "    when(col(\"MIN_EDULEVELS_NAME\").isNull(), \"No Education Listed\")\n",
        "    .otherwise(col(\"MIN_EDULEVELS_NAME\"))\n",
        ")\n",
        "\n",
        "# Employment Type Name\n",
        "\n",
        "selected_df = selected_df.withColumn(\n",
        "  \"EMPLOYMENT_TYPE_NAME\",\n",
        "    when(col(\"EMPLOYMENT_TYPE_NAME\") == \"Part-time / full-time\",\"Flexible\")\n",
        "    .when(col(\"EMPLOYMENT_TYPE_NAME\") == \"Part-time (â‰¤ 32 hours)\",\"Part-Time\")\n",
        "    .when(col(\"EMPLOYMENT_TYPE_NAME\") == \"Full-time (> 32 hours)\",\"Full-Time\")\n",
        "    .when(col(\"EMPLOYMENT_TYPE_NAME\").isNull(), \"Full-Time\")\n",
        "    .otherwise(col(\"EMPLOYMENT_TYPE_NAME\"))\n",
        ")\n",
        "\n",
        "# Min Years Experience\n",
        "selected_df = selected_df.withColumn(\n",
        "    \"MIN_YEARS_EXPERIENCE\",\n",
        "    when(col(\"MIN_YEARS_EXPERIENCE\").isNull(), 0)\n",
        "    .otherwise(col(\"MIN_YEARS_EXPERIENCE\"))\n",
        ")\n",
        "\n",
        "# Salary to\n",
        "selected_df = selected_df.withColumn(\n",
        "    \"SALARY_TO\",\n",
        "    when(col(\"SALARY_TO\").isNull(), median_to)\n",
        "    .otherwise(col(\"SALARY_TO\"))\n",
        ")\n",
        "\n",
        "# Salary from\n",
        "selected_df = selected_df.withColumn(\n",
        "    \"SALARY_FROM\",\n",
        "    when(col(\"SALARY_FROM\").isNull(), median_from)\n",
        "    .otherwise(col(\"SALARY_FROM\"))\n",
        ")\n",
        "\n",
        "# Salary \n",
        "selected_df = selected_df.withColumn(\n",
        "    \"SALARY\",\n",
        "    when(col(\"SALARY\").isNull(), median_salary)\n",
        "    .otherwise(col(\"SALARY\"))\n",
        ")\n",
        "\n",
        "# City Name\n",
        "selected_df = selected_df.withColumn(\n",
        "  \"CITY_NAME\",\n",
        "    when(col(\"CITY_NAME\").isNull(), \"Unknown\")\n",
        "    .otherwise(col(\"CITY_NAME\"))\n",
        ")\n",
        "\n",
        "# MSA Name\n",
        "selected_df = selected_df.withColumn(\n",
        "  \"MSA_NAME\",\n",
        "    when(col(\"MSA_NAME\").isNull(), \"Unknown\")\n",
        "    .otherwise(col(\"MSA_NAME\"))\n",
        ")\n",
        "\n",
        "# State Name\n",
        "selected_df = selected_df.withColumn(\n",
        "  \"STATE_NAME\",\n",
        "    when(col(\"STATE_NAME\").isNull(), \"Unknown\")\n",
        "    .otherwise(col(\"STATE_NAME\"))\n",
        ")\n",
        "\n",
        "# NAICS2_NAME \n",
        "selected_df = selected_df.withColumn(\n",
        "  \"NAICS2_NAME\",\n",
        "    when(col(\"NAICS2_NAME\").isNull(), \"Unknown\")\n",
        "    .otherwise(col(\"NAICS2_NAME\"))\n",
        ")\n",
        "\n",
        "# NAICS3_NAME \n",
        "selected_df = selected_df.withColumn(\n",
        "  \"NAICS3_NAME\",\n",
        "    when(col(\"NAICS3_NAME\").isNull(), \"Unknown\")\n",
        "    .otherwise(col(\"NAICS3_NAME\"))\n",
        ")\n",
        "\n",
        "# NAICS4_NAME \n",
        "selected_df = selected_df.withColumn(\n",
        "  \"NAICS4_NAME\",\n",
        "    when(col(\"NAICS4_NAME\").isNull(), \"Unknown\")\n",
        "    .otherwise(col(\"NAICS4_NAME\"))\n",
        ")\n",
        "\n",
        "# NAICS5_NAME \n",
        "selected_df = selected_df.withColumn(\n",
        "  \"NAICS5_NAME\",\n",
        "    when(col(\"NAICS5_NAME\").isNull(), \"Unknown\")\n",
        "    .otherwise(col(\"NAICS5_NAME\"))\n",
        ")\n",
        "\n",
        "# NAICS6_NAME \n",
        "selected_df = selected_df.withColumn(\n",
        "  \"NAICS6_NAME\",\n",
        "    when(col(\"NAICS6_NAME\").isNull(), \"Unknown\")\n",
        "    .otherwise(col(\"NAICS6_NAME\"))\n",
        ")\n",
        "\n",
        "#STATE ABBREVIATION\n",
        "selected_df = selected_df.withColumn(\n",
        "  \"STATE_ABBREVIATION\",\n",
        "    when(col(\"STATE_ABBREVIATION\").isNull(), \"Unknown\")\n",
        "    .otherwise(col(\"STATE_ABBREVIATION\"))\n",
        ")"
      ],
      "id": "b3c9de36",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pdf = selected_df.toPandas()\n",
        "\n",
        "pdf.to_csv(\"./data/lightcast_cleaned.csv\", index=False)\n",
        "\n",
        "pdf.head(15)\n",
        "\n",
        "print(\"Data Cleaning Complete. Rows retained:\", len(pdf))"
      ],
      "id": "0708f45c",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}